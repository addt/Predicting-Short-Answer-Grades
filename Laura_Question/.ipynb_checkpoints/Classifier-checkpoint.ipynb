{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifier for question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "%matplotlib inline\n",
    "\n",
    "import re\n",
    "import math\n",
    "import string\n",
    "from collections import Counter\n",
    "from __future__ import division\n",
    "from time import time\n",
    "import logging\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "\n",
    "import itertools\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from nltk import FreqDist\n",
    "from nltk.stem import PorterStemmer\n",
    "from string import punctuation\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from spacy.en import English\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#From scikit's examples\n",
    "#http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py\n",
    "\n",
    "class_names = [1, 2, 3, 4, 5]\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read_file is a helper function to get the '|' delimited CSV into a data frame\n",
    "def read_file(filename):\n",
    "    #get the file\n",
    "    df = pd.read_csv(filename, error_bad_lines=False, encoding = 'mbcs')\n",
    "    \n",
    "    #Force KIScore to int, otherwise reverts to float. Same for Answer. Forcing NaN to unicode\n",
    "    df['KIScore'] = df['KIScore'].astype(int)\n",
    "    df['Answer'] = df['Answer'].astype(str)\n",
    "    # Filters if needed later on\n",
    "    #filtered_data = df[\"Answer\"].notnull()\n",
    "    #filtered_data = df[df[\"KIScore\"] != 1 & df['Answer'].notnull() & df[\"KIScore\"].notnull()]\n",
    "    #df_narrative = df[filtered_data]\n",
    "    return df\n",
    "\n",
    "#reads in the training data into a panda - Steve \n",
    "#(code based on ANLP Notebook Intro to Pandas by Marti Hearst and Andrea Gagliano)\n",
    "def read_training_data(filename):\n",
    "    df_narrative = read_file(filename)\n",
    "    return df_narrative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#breaks the panda into a training set and a dev set - Currently only genereates dev and test data\n",
    "#Modify the function later to keep some data as test data as well\n",
    "\n",
    "def get_train_and_dev_sets(full_data, percent_dev):\n",
    "    #randomize the indices\n",
    "    random_index = np.random.permutation(full_data.index)\n",
    "    full_data_shuffled = full_data.ix[random_index, ['WISEID', 'Answer', 'KIScore']]\n",
    "    full_data_shuffled.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    #break down the counts for the shuffled data\n",
    "    rows, columns = full_data_shuffled.shape\n",
    "    train_size = round(rows*(1 - percent_dev))\n",
    "    dev_size   = round(rows*percent_dev)\n",
    "    \n",
    "    #separate the training data from the development data\n",
    "    train_data = full_data_shuffled.loc[:train_size]\n",
    "    dev_data = full_data_shuffled.loc[train_size:dev_size+train_size].reset_index(drop=True)\n",
    "\n",
    "    return train_data, dev_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reads in the test file into a panda\n",
    "def read_test_data(filename):\n",
    "    #get the file\n",
    "    df = read_file(filename)\n",
    "    return df\n",
    "\n",
    "df = read_training_data(\"Laura1.csv\")\n",
    "train_set, dev_set = get_train_and_dev_sets(df,.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Norvig's spell checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEXT = open('big.txt').read()\n",
    "\n",
    "def tokens(text):\n",
    "    \"List all the word tokens (consecutive letters) in a text. Normalize to lowercase.\"\n",
    "    return re.findall('[a-z]+', text.lower())\n",
    "\n",
    "def tokens_target(text):\n",
    "    \"List all the word tokens (consecutive letters) in a text. Normalize to lowercase.\"\n",
    "    words = re.findall('[a-z]+', text.lower())\n",
    "    tagged_POS_sents = nltk.pos_tag(words) # tags sents\n",
    "    #normed_tagged_words = [wnl.lemmatize(word[0].lower()) for sent in tagged_POS_sents\n",
    "                           #for word in sent \n",
    "                           #if word[0].lower() not in nltk.corpus.stopwords.words('english')\n",
    "                           #and word[0] not in punctuation # remove punctuation\n",
    "                           #and not re.search(r'''^[\\.,;\"'?!():\\-_`]+$''', word[0])\n",
    "                           #and word[1].startswith('N')]  # include only nouns\n",
    "    #print(tagged_POS_sents)\n",
    "    return words\n",
    "    if (len(tagged_POS_sents) > 1):\n",
    "        normed_tagged_words = [word[0].lower() for word in tagged_POS_sents\n",
    "                              if (word[1].startswith('N') or word[1].startswith('J') or word[1].startswith('V'))]\n",
    "        return normed_tagged_words\n",
    "    else:\n",
    "        return words\n",
    "\n",
    "WORDS = tokens(TEXT)\n",
    "\n",
    "COUNTS = Counter(WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def correct(word):\n",
    "    \"Find the best spelling correction for this word.\"\n",
    "    # Prefer edit distance 0, then 1, then 2; otherwise default to word itself.\n",
    "    candidates = (known(edits0(word)) or \n",
    "                  known(edits1(word)) or \n",
    "                  known(edits2(word)) or \n",
    "                  [word])\n",
    "    return word\n",
    "    #return max(candidates, key=COUNTS.get)\n",
    "\n",
    "# Show what happens in the case of ties\n",
    "def correct_under_hood (word):\n",
    "    candidates = (known(edits0(word)) or \n",
    "                  known(edits1(word)) or \n",
    "                  known(edits2(word)) or \n",
    "                  [word])\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def known(words):\n",
    "    \"Return the subset of words that are actually in the dictionary.\"\n",
    "    return {w for w in words if w in COUNTS}\n",
    "\n",
    "def edits0(word): \n",
    "    \"Return all strings that are zero edits away from word (i.e., just word itself).\"\n",
    "    return {word}\n",
    "\n",
    "def edits2(word):\n",
    "    \"Return all strings that are two edits away from this word.\"\n",
    "    return {e2 for e1 in edits1(word) for e2 in edits1(e1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def edits1(word):\n",
    "    \"Return all strings that are one edit away from this word.\"\n",
    "    pairs      = splits(word)\n",
    "    deletes    = [a+b[1:]           for (a, b) in pairs if b]\n",
    "    transposes = [a+b[1]+b[0]+b[2:] for (a, b) in pairs if len(b) > 1]\n",
    "    replaces   = [a+c+b[1:]         for (a, b) in pairs for c in alphabet if b]\n",
    "    inserts    = [a+c+b             for (a, b) in pairs for c in alphabet]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def splits(word):\n",
    "    \"Return a list of all possible (first, rest) pairs that comprise word.\"\n",
    "    return [(word[:i], word[i:]) \n",
    "            for i in range(len(word)+1)]\n",
    "\n",
    "alphabet = 'abcdefghijklmnopqrstuvwxyz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WISEID</th>\n",
       "      <th>Answer</th>\n",
       "      <th>KIScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>118564.0</td>\n",
       "      <td>because dark colored fabric heats up</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150058.0</td>\n",
       "      <td>she sod us the light fabric and the light colo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>118358.0</td>\n",
       "      <td>because the sun only puts to much heat on dark...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>139878.0</td>\n",
       "      <td>i think the best way is using light colored fa...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>136509.0</td>\n",
       "      <td>because light colored paint does not asorb hea...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     WISEID                                             Answer  KIScore\n",
       "0  118564.0               because dark colored fabric heats up        2\n",
       "1  150058.0  she sod us the light fabric and the light colo...        2\n",
       "2  118358.0  because the sun only puts to much heat on dark...        2\n",
       "3  139878.0  i think the best way is using light colored fa...        2\n",
       "4  136509.0  because light colored paint does not asorb hea...        3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spell_checker = lambda x : ' '.join(i for i in list(map(correct, tokens(x))))\n",
    "normalizer = lambda x : ' '.join(i for i in list(map(correct, tokens_target(x))))\n",
    "train_set['Answer'] = train_set['Answer'].apply(normalizer)\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WISEID</th>\n",
       "      <th>Answer</th>\n",
       "      <th>KIScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>118458.0</td>\n",
       "      <td>i used the white for both sides of the car bec...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>118364.0</td>\n",
       "      <td>the light colored paint will reflect the sun away</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>136413.0</td>\n",
       "      <td>she wouldn t want the inside of her car to get...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>118341.0</td>\n",
       "      <td>using light colored paints and fabrics reflect...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>153823.0</td>\n",
       "      <td>light colored fabric because the lighter the c...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     WISEID                                             Answer  KIScore\n",
       "0  118458.0  i used the white for both sides of the car bec...        2\n",
       "1  118364.0  the light colored paint will reflect the sun away        3\n",
       "2  136413.0  she wouldn t want the inside of her car to get...        2\n",
       "3  118341.0  using light colored paints and fabrics reflect...        4\n",
       "4  153823.0  light colored fabric because the lighter the c...        4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_set['Answer'] = dev_set['Answer'].apply(normalizer)\n",
    "dev_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_dfs_to_arrays(train_set, dev_set):\n",
    "    vec = CountVectorizer(ngram_range=(1, 4), token_pattern=r'\\b\\w+\\b', stop_words=\"english\", max_features=5000)\n",
    "    arr_train_feature_sparse = vec.fit_transform(train_set[\"Answer\"].values.astype(str))\n",
    "    arr_train_feature = arr_train_feature_sparse.toarray()\n",
    "    \n",
    "    arr_dev_feature_sparse = vec.transform(dev_set[\"Answer\"].values.astype(str))\n",
    "    arr_dev_feature = arr_dev_feature_sparse.toarray()\n",
    "        \n",
    "    return arr_train_feature, arr_dev_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr_train, arr_dev = transform_dfs_to_arrays(train_set, dev_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#From Kaggle\n",
    "\n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "        #self.snow = SnowballStemmer('english')\n",
    "    \n",
    "    #this code will filter punctuation from a word and rejoin it together (\"they're\" becomes \"theyre\")\n",
    "    def __preprocess(self, doc):\n",
    "       filter_punc = lambda t: ''.join([x.lower() for x in t if x.isalpha()])\n",
    "       words = [x for x in map(filter_punc, doc.split()) if x]\n",
    "       review = \"\"\n",
    "       for w in words:\n",
    "           review = review+\" \"+w\n",
    "       return review\n",
    "    \n",
    "    #Multiple attempts to select lemmas and stems from a word token (using NLTK)\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(self.__preprocess(doc))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68632707774798929"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = RandomForestClassifier(random_state=1, n_estimators = 100)\n",
    "clf3 = GaussianNB()\n",
    "clf4 = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n",
    "                                      max_depth=1, random_state=0)\n",
    "clf6 = SVC(C = 1000000.0, gamma='auto', kernel='rbf', probability = True)\n",
    "clf8 = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(5, 2), random_state=1)\n",
    "clf9 = SGDRegressor(shuffle = True, verbose = 0)\n",
    "\n",
    "eclf_w = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), \n",
    "                                    ('clf6', clf6),\n",
    "                                   ('clf4', clf4), ('clf8', clf8)], \n",
    "                                                  weights=[3, 5, 1, 2, 1], voting = 'soft')\n",
    "\n",
    "eclf_w_predictor = eclf_w.fit(arr_train, train_set.KIScore)\n",
    "w_predicted = eclf_w_predictor.predict(arr_dev)\n",
    "accuracy_score(dev_set.KIScore, w_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final classifier for question 1 - I made the choice of using an ensemble classifier with some of the most accurate classifiers I experimented with. I used soft voting(I got the best weights for the classifier by running a brute force search for all the weight combinations - code in notebook in parent directory). Further I use sci kits Feature union method to add some specific features to my classifier that were relevant to this question. I would have liked to play around with more with feature combinations, but unfortunately did not have the time to finish to perform that.\n",
    "\n",
    "Further, the similarity of the answrs across the categories makes it really hard to decide on the best features to be used and a significant amount of time was spent on feature selection. In spite of that, as the confusion matrix shows the largest error is when predciting a grade 3 as grade 2.\n",
    "\n",
    "Future work - Thinking of working with Keras to see how that performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_overlaps_greedy(context, synsets_signatures, pos=None):\n",
    "    \"\"\"\n",
    "    Calculate overlaps between the context sentence and the synset_signature\n",
    "    and returns the synset with the highest overlap.\n",
    "    \n",
    "    :param context: ``context_sentence`` The context sentence where the ambiguous word occurs.\n",
    "    :param synsets_signatures: ``dictionary`` A list of words that 'signifies' the ambiguous word.\n",
    "    :param pos: ``pos`` A specified Part-of-Speech (POS).\n",
    "    :return: ``lesk_sense`` The Synset() object with the highest signature overlaps.\n",
    "    \"\"\"\n",
    "    max_overlaps = 0\n",
    "    lesk_sense = None\n",
    "    for ss in synsets_signatures:\n",
    "        if pos and str(ss.pos()) != pos: # Skips different POS.\n",
    "            continue\n",
    "        overlaps = set(synsets_signatures[ss]).intersection(context)\n",
    "        #print(overlaps)\n",
    "        if len(overlaps) > max_overlaps:\n",
    "            lesk_sense = ss\n",
    "            max_overlaps = len(overlaps)  \n",
    "    return lesk_sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lesk(context_sentence, ambiguous_word, pos=None, dictionary=None):\n",
    "    \"\"\"\n",
    "    This function is the implementation of the original Lesk algorithm (1986).\n",
    "    It requires a dictionary which contains the definition of the different\n",
    "    sense of each word. See http://goo.gl/8TB15w\n",
    "\n",
    "        >>> from nltk import word_tokenize\n",
    "        >>> sent = word_tokenize(\"I went to the bank to deposit money.\")\n",
    "        >>> word = \"bank\"\n",
    "        >>> pos = \"n\"\n",
    "        >>> lesk(sent, word, pos)\n",
    "        Synset('bank.n.07')\n",
    "    \n",
    "    :param context_sentence: The context sentence where the ambiguous word occurs.\n",
    "    :param ambiguous_word: The ambiguous word that requires WSD.\n",
    "    :param pos: A specified Part-of-Speech (POS).\n",
    "    :param dictionary: A list of words that 'signifies' the ambiguous word.\n",
    "    :return: ``lesk_sense`` The Synset() object with the highest signature overlaps.\n",
    "    \"\"\"\n",
    "    if not dictionary:\n",
    "        #print(\"here\")\n",
    "        dictionary = {}\n",
    "        for ss in wn.synsets(ambiguous_word):\n",
    "            #print(ss)\n",
    "            #print(ss.pos())\n",
    "            #print(ss.definition().split())\n",
    "            dictionary[ss] = ss.definition().split()\n",
    "    best_sense = compare_overlaps_greedy(context_sentence, dictionary, pos)\n",
    "    return best_sense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos_tags = {'NN' : 'n',\n",
    "           'NNS' : 'n',\n",
    "           'NNP' : 'n',\n",
    "           'NNPS' : 'n',\n",
    "           'JJ' : 'a',\n",
    "           'JJR' : 'a',\n",
    "           'JJS' : 'a',\n",
    "           'VB' : 'v',\n",
    "           'VBD' : 'v',\n",
    "           'VBG' : 'v',\n",
    "           'VBN' : 'v',\n",
    "           'VBZ' : 'v',\n",
    "           'VBP' : 'v'}\n",
    "\n",
    "from collections import defaultdict\n",
    "def freq_normed_unigrams(sents):\n",
    "    wnl = WordNetLemmatizer() # to get word stems\n",
    "    \n",
    "    tagged_POS_sents = [nltk.pos_tag(word_tokenize(sent)) for sent in sents] # tags sents\n",
    "    \n",
    "    normed_tagged_words = [wnl.lemmatize(word[0].lower()) for sent in tagged_POS_sents\n",
    "                           for word in sent \n",
    "                           if word[0].lower() not in nltk.corpus.stopwords.words('english')\n",
    "                           and word[0] not in punctuation # remove punctuation\n",
    "                           and not re.search(r'''^[\\.,;\"'?!():\\-_`]+$''', word[0])\n",
    "                           and (word[1].startswith('N') \n",
    "                                or word[1].startswith('J')\n",
    "                                or word[1].startswith('V'))]  # include only nouns. verbs and adjectives\n",
    "\n",
    "    top_normed_unigrams = [word for (word, count) in nltk.FreqDist(normed_tagged_words).most_common(15)]\n",
    "    return top_normed_unigrams\n",
    "\n",
    "def categories_from_hypernyms(sents):\n",
    "    topic_list = []\n",
    "    termlist = freq_normed_unigrams(sents) # get top unigrams\n",
    "    hypterms = []\n",
    "    hypterms_dict = defaultdict(list)\n",
    "    for term in termlist:                  # for each term\n",
    "        wn_tag = pos_tags.get(nltk.pos_tag([term])[0][1], 'n')\n",
    "        s = wn.synsets(term.lower(), wn_tag)  # get its nominal synsets\n",
    "        \n",
    "        sn = lesk(sents[0], term, wn_tag)\n",
    "        for syn in s:\n",
    "            if syn is not None:\n",
    "                for hyp in syn.hypernyms():    # It has a list of hypernyms\n",
    "                    hypterms = hypterms + [hyp.name]      # Extract the hypernym name and add to list\n",
    "                    #hypterms_dict[hyp.name].append(term)  # Extract examples and add them to dict\n",
    "                    hypterms_dict[hyp.name].append(hyp.lemmas()[0].name()+\":\"+term)\n",
    "                    \n",
    "    hypfd = nltk.FreqDist(hypterms)             # After going through all the nouns, print out the hypernyms \n",
    "    for (name, count) in hypfd.most_common(20):  # that have accumulated the most counts (have seen the most descendents)\n",
    "        #topic_list.extend([hyp.lemmas()[0].name()+\":\"+term])\n",
    "        #print( name(), '({0})'.format(count))\n",
    "        #print ('\\t', ', '.join(set(hypterms_dict[name])))  # show the children found for each hypernym\n",
    "        topic_list.extend([set(hypterms_dict[name])])\n",
    "        #print ()\n",
    "    return [item for sublist in topic_list for item in sublist]\n",
    "    #return topic_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parser = English()\n",
    "\n",
    "# A custom stoplist\n",
    "STOPLIST = set(stopwords.words('english') + [\"n't\", \"'s\", \"'m\", \"ca\"] + list(ENGLISH_STOP_WORDS))\n",
    "# List of symbols we don't care about\n",
    "SYMBOLS = \" \".join(string.punctuation).split(\" \") + [\"-----\", \"---\", \"...\", \"“\", \"”\", \"'ve\"]\n",
    "\n",
    "#Adding a spacy tokenizer - from tutorials\n",
    "def tokenizeText(sample):\n",
    "\n",
    "    # get the tokens using spaCy\n",
    "    tokens = parser(sample)\n",
    "\n",
    "    # lemmatize\n",
    "    lemmas = []\n",
    "    for tok in tokens:\n",
    "        lemmas.append(tok.lemma_.lower().strip() if tok.lemma_ != \"-PRON-\" else tok.lower_)\n",
    "    tokens = lemmas\n",
    "\n",
    "    # stoplist the tokens\n",
    "    tokens = [tok for tok in tokens if tok not in STOPLIST]\n",
    "\n",
    "    # stoplist symbols\n",
    "    tokens = [tok for tok in tokens if tok not in SYMBOLS]\n",
    "\n",
    "    # remove large strings of whitespace\n",
    "    while \"\" in tokens:\n",
    "        tokens.remove(\"\")\n",
    "    while \" \" in tokens:\n",
    "        tokens.remove(\" \")\n",
    "    while \"\\n\" in tokens:\n",
    "        tokens.remove(\"\\n\")\n",
    "    while \"\\n\\n\" in tokens:\n",
    "        tokens.remove(\"\\n\\n\")\n",
    "\n",
    "    return tokens\n",
    "\n",
    "def cleanText(text):\n",
    "    # get rid of newlines\n",
    "    text = text.strip().replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "    \n",
    "    # replace twitter @mentions\n",
    "    mentionFinder = re.compile(r\"@[a-z0-9_]{1,15}\", re.IGNORECASE)\n",
    "    text = mentionFinder.sub(\"@MENTION\", text)\n",
    "    \n",
    "    # replace HTML symbols\n",
    "    text = text.replace(\"&amp;\", \"and\").replace(\"&gt;\", \">\").replace(\"&lt;\", \"<\")\n",
    "    \n",
    "    # lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cleanText' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-35b5dd42d89f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 207\u001b[1;33m \u001b[0mp_predictor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipeline2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Answer'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKIScore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp_predictor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdev_set\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Answer'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    266\u001b[0m             \u001b[0mThis\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m         \"\"\"\n\u001b[1;32m--> 268\u001b[1;33m         \u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    269\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    232\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"fit_transform\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m                 \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m                 \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    735\u001b[0m             delayed(_fit_transform_one)(trans, name, weight, X, y,\n\u001b[0;32m    736\u001b[0m                                         **fit_params)\n\u001b[1;32m--> 737\u001b[1;33m             for name, trans, weight in self._iter())\n\u001b[0m\u001b[0;32m    738\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    757\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 758\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    606\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 608\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    609\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 571\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, name, weight, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    578\u001b[0m                        **fit_params):\n\u001b[0;32m    579\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit_transform'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    299\u001b[0m         \"\"\"\n\u001b[0;32m    300\u001b[0m         \u001b[0mlast_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 301\u001b[1;33m         \u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    302\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlast_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit_transform'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mlast_step\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    232\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"fit_transform\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m                 \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m                 \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    495\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 497\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-34-35b5dd42d89f>\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X, **transform_params)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mtransform_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcleanText\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-34-35b5dd42d89f>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mtransform_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcleanText\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cleanText' is not defined"
     ]
    }
   ],
   "source": [
    "ps = PorterStemmer()\n",
    "lightpattern = re.compile(r\"^(?=.*?\\b(light|bright|white)\\b)(?=.*?\\b(color|colors|colored|cover)\\b)(?=.*?\\b(deflect|reflect|reflects)\\b).*$\")\n",
    "darkpattern = re.compile(r\"^(?=.*?\\b(dark|black|darker)\\b)(?=.*?\\b(color|colors|colored)\\b)(?=.*?\\b(absorb|attract|obsorb|absorbs|obsorbs|obsorbes)\\b).*$\")\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lb = LabelEncoder()\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 3), tokenizer=tokenizeText,  \n",
    "                                              max_df=0.25, max_features= 15000, token_pattern=r'\\b\\w+\\b', \n",
    "                                              stop_words=\"english\")\n",
    "\n",
    "class TextStats(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Extract features from each document for DictVectorizer\"\"\"\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, posts):\n",
    "        return [{'length': len(text)}\n",
    "                for text in posts.tolist()]\n",
    "\n",
    "class CleanTextTransformer(TransformerMixin):\n",
    "    \"\"\"\n",
    "    Convert text to cleaned text\n",
    "    \"\"\"\n",
    "\n",
    "    def transform(self, X, **transform_params):\n",
    "        return [cleanText(text) for text in X]\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {}\n",
    "\n",
    "class Keywords_Radiation(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Extract features from each document for DictVectorizer\"\"\"\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, posts):\n",
    "        return [{'Radiation': 'radiat' in [ps.stem(i) for i in text.split()]\n",
    "                or 'energi' in [ps.stem(i) for i in text.split()]}\n",
    "                for text in posts.tolist()]\n",
    "    \n",
    "class Keywords_Dark(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Extract features from each document for DictVectorizer\"\"\"\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, posts):\n",
    "        return [{'Dark': ('dark' in [ps.stem(i) for i in text.split()]\n",
    "                          or 'black' in [ps.stem(i) for i in text.split()])\n",
    "                and 'absorb' in [ps.stem(i) for i in text.split()]}\n",
    "                for text in posts.tolist()]\n",
    "    \n",
    "class Keywords_Light(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Extract features from each document for DictVectorizer\"\"\"\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, posts):\n",
    "        return [{'Dark': ('light' in [ps.stem(i) for i in text.split()]\n",
    "                          or 'white' in [ps.stem(i) for i in text.split()])\n",
    "                and 'reflect' in [ps.stem(i) for i in text.split()]}\n",
    "                for text in posts.tolist()]\n",
    "    \n",
    "class Phrase_Light(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Extract features from each document for DictVectorizer\"\"\"\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, posts):\n",
    "        return [{'Phrase': lightpattern.match(text) is not None}\n",
    "                for text in posts.tolist()]\n",
    "    \n",
    "class Phrase_Dark(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Extract features from each document for DictVectorizer\"\"\"\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, posts):\n",
    "        return [{'Phrase': darkpattern.match(text) is not None}\n",
    "                for text in posts.tolist()]\n",
    "    \n",
    "class Keywords_Hyp(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Extract features from each document for DictVectorizer\"\"\"\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, posts):\n",
    "        return [' '.join(x for x in categories_from_hypernyms([text]))\n",
    "                for text in posts.tolist()]\n",
    "    \n",
    "class Keywords_Albedo(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Extract features from each document for DictVectorizer\"\"\"\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, posts):\n",
    "        return [{'Albedo': 'albedo' in [ps.stem(i) for i in text.split()]}\n",
    "                for text in posts.tolist()]\n",
    "    \n",
    "class Trap_Radiation(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Extract features from each document for DictVectorizer\"\"\"\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, posts):\n",
    "        return [{'Trap': 'trap' in [ps.stem(i) for i in text.split()]\n",
    "                               or 'keep' in [ps.stem(i) for i in text.split()]}\n",
    "                for text in posts.tolist()]\n",
    "    \n",
    "#Required to convert a sparse matrix to a dense matrix. Vectorizers give out a sparse matrix but some \n",
    "#classifiers need a dense matrix to perform classification\n",
    "class DenseTransformer(TransformerMixin):\n",
    "\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X.todense()\n",
    "\n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        self.fit(X, y, **fit_params)\n",
    "        return self.transform(X)\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    \n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "pipeline2 = Pipeline([\n",
    "    ('features', FeatureUnion(\n",
    "        transformer_list=[\n",
    "        ('cleaner', Pipeline([\n",
    "                    ('clean', CleanTextTransformer()),  # returns a list of dicts\n",
    "                    ('vect', CountVectorizer(tokenizer=tokenizeText, ngram_range=(1,1)))  # list of dicts -> feature matrix\n",
    "        ])),\n",
    "        ('body_stats', Pipeline([\n",
    "                    ('stats', TextStats()),  # returns a list of dicts\n",
    "                    ('vect', DictVectorizer())  # list of dicts -> feature matrix\n",
    "        ])),\n",
    "        ('key_words_dark', Pipeline([ # Give low weight\n",
    "                    ('Dark', Keywords_Dark()),  # returns a list of dicts\n",
    "                    ('vect', DictVectorizer())  # list of dicts -> feature matrix\n",
    "        ])),\n",
    "        ('key_words_light', Pipeline([ # Give low weight\n",
    "                    ('Light', Keywords_Light()),  # returns a list of dicts\n",
    "                    ('vect', DictVectorizer())  # list of dicts -> feature matrix\n",
    "        ])),            \n",
    "        #('key_words_albedo', Pipeline([ # Give low weight\n",
    "                    #('Albedo', Keywords_Albedo()),  # returns a list of dicts\n",
    "                    #('vect', DictVectorizer())  # list of dicts -> feature matrix\n",
    "        #])),\n",
    "        ('key_words_radiate', Pipeline([ # Give low weight\n",
    "                    ('Radiation', Keywords_Radiation()),  # returns a list of dicts\n",
    "                    ('vect', DictVectorizer())  # list of dicts -> feature matrix\n",
    "        ])),\n",
    "        ('key_words_trap', Pipeline([ # Give low weight\n",
    "                    ('Trap', Trap_Radiation()),  # returns a list of dicts\n",
    "                    ('vect', DictVectorizer())  # list of dicts -> feature matrix\n",
    "        ])),\n",
    "        #('key_words_hyp', Pipeline([ # Give low weight\n",
    "                    #('Hyp', Keywords_Hyp()),  # returns a list of dicts\n",
    "                    #('vect', CountVectorizer(ngram_range=(1, 3), tokenizer=LemmaTokenizer(),  \n",
    "                                              #max_df=0.25, max_features= 15000, token_pattern=r'\\b\\w+\\b', \n",
    "                                              #stop_words=\"english\"))\n",
    "        #])),\n",
    "        ('light_phrase', Pipeline([ # Give low weight\n",
    "                    ('PhraseLight', Phrase_Light()),  # returns a list of dicts\n",
    "                    ('vect', DictVectorizer())  # list of dicts -> feature matrix\n",
    "        ])),\n",
    "        ('dark_phrase', Pipeline([ # Give low weight\n",
    "                    ('PhraseDark', Phrase_Dark()),  # returns a list of dicts\n",
    "                    ('vect', DictVectorizer())  # list of dicts -> feature matrix\n",
    "        ])),            \n",
    "        ('bag_of', Pipeline([\n",
    "                    ('vect', vectorizer)\n",
    "                    #('tfidf_transformer', TfidfTransformer(use_idf = True, norm='l2'))\n",
    "        ]))\n",
    "    ],\n",
    "    # weight components in FeatureUnion\n",
    "        #transformer_weights={\n",
    "            #'body_stats': 1.0,        \n",
    "            #'key_words_dark': 1.0,\n",
    "            #'key_words_light': 1.0,\n",
    "            #'key_words_albedo': 1.0,        \n",
    "            #'key_words_radiate': 1.0,\n",
    "            #'key_words_trap': 1.0,\n",
    "            #'bag_of': 1.0        \n",
    "        #},\n",
    "    )),\n",
    "    ('to_dense', DenseTransformer()), \n",
    "    ('feature_selection', SelectFromModel(ExtraTreesClassifier(), prefit=False)),\n",
    "    #('dim', LinearDiscriminantAnalysis(n_components=2)),\n",
    "    #('clf', SVC(kernel='linear'))  # classifier\n",
    "    ('clf', eclf_w)  # classifier\n",
    "])\n",
    "\n",
    "\n",
    "p_predictor = pipeline2.fit(train_set['Answer'], train_set.KIScore)\n",
    "\n",
    "predicted = p_predictor.predict(dev_set['Answer'].values)\n",
    "accuracy_score(dev_set.KIScore, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.72654155496\n",
      "Cohen's Kappa:  0.578997454908\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \",accuracy_score(dev_set.KIScore, predicted))\n",
    "print(\"Cohen's Kappa: \",cohen_kappa_score(dev_set.KIScore, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[ 19   1   0   0   0]\n",
      " [  0 164   9   2   0]\n",
      " [  0  41  50   5   0]\n",
      " [  0   5  20  35   0]\n",
      " [  0   0   4  15   3]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUwAAAEpCAYAAAD4Vxu2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XecFdX5x/HPdxdQkKAoTVjEQhcEFRClWwAVwUQRRBRL\nYoslaqKxxUqsCT9LNJoYW1QUNSIWmiiISFGsIBZUqoAUC0XafX5/3Nl1Wdnd2Xv37sxdnjeveXGn\nnucuw7NnzsycIzPDOedc6XKiDsA557KFJ0znnAvJE6ZzzoXkCdM550LyhOmccyF5wnTOuZA8YTok\nfSXp8Ire17ls4wkz5iQNljRd0lpJyyS9Lem8qONybkfkCTPGJF0GjABuA+qbWQPgXOAwSVWL2cf/\nTctIUm7UMbjs4P+5YkpSLeAG4Dwz+5+ZrQMwsw/M7FQz2xxs97Ck+yS9LOlHoKekYyTNlvS9pAWS\nrity7FMlfS3pW0lXFVknSX+W9EWwfqSk3cLsu53vUGwckppISkg6LVi3ovDxJHWUNCvY9xtJdwbL\nH5F0SfC5YXCM84L5/SStKnSMfpLek7RG0lRJbQut+0rS5ZI+ANZKypF0haTFkn6Q9ImkXmH/vdwO\nwsx8iuEE9AE2ATmlbPcwsAboHMxXA7oD+wfzbYBvgP7BfGvgR6ALUBX4W1DO4cH6i4FpwJ7B+vuB\nJ8Psu53YSoqjCZAAHghiPgD4CWgRrJ8GnBJ8rgF0Cj6fAYwOPp8MfA48VWjd/4LPBwLLgQ6AgFOB\nr4CqwfqvgNlAQ2AnoDmwkGRNHmAvYJ+ozwOf4jV5DTO+6gArzSyRv0DSW0Ftab2kroW2HW1m0wHM\nbJOZTTGzOcH8x8BIoEew7QnAGDN7y5K11GuBwh0KnANcbWbfBOtvBE4MLvVL23cbpcRBsO/1Qcwf\nAh8A7YJ1m4CmkvYws/VmNjNYPhnI/+7dgdtJJnCCY08OPv8O+KeZvWNJjwMbgc6Fyr/LzJaa2UZg\nK8nE3UZSFTNbaGZfFffd3I7JE2Z8rQLqFG6TNLMuZlY7WFf4325R4R0ldZI0KbjM/Y5kEqwTrG5Y\neHszWx8cL18T4H+SVktaDcwFNgP1Q+y7jVLiyLe80Of1QM3g81lAC2CepBmSjg3K/BJYJ+lAoBvw\nErBUUnO2TZhNgMvyv4ekNUBe8B3yLS70XeYDfwCuB5ZLelLSnsV9N7dj8oQZX2+TrBENCLFt0Vre\nk8ALQCMz243kZa+Cdd8AjfM3lFQD2KPQvguBo81s92CqbWa7mNk3IfYtqqQ4Sv5CZvPNbIiZ1SVZ\ni3xWUvVg9WTgRJKX198AU4BhwG7A+8E2i4DhRb5HTTN7unAxRcocaWbdSCZbgFvDxOp2HJ4wY8rM\nvid5OXyfpBMk1QxuyLQn2aZXkprAGjPbLKkTMKTQumeBfpLy77TfyLZJ7AHgr5L2ApBUV1L/kPuW\nJQ5K2lfSKZLya6Pfk0xu+c0TU4ALgr8B3gjmp5pZfhL8F3BuUC6SdgluQu1STHnNJfWSVI1kc8CG\nQuU5B3jCjDUzuwO4FLgcWBZM9wfz00rY9XzgJknfA9cABbUqM5sL/B54ClhK8pJ6caF97wJGA+OD\n/acBnULuGzqO/HBKmO8LzJH0A8lHqwYFbY2QrGHW5OfL76lA9ULzmNm7JNsx7w2aFj4jWQstruyd\nSNYovw2+W13gyhK+m9sB6edfyM4550riNUznnAvJE6ZzzoXkCdM550LyhOmccyFViToAAEl+58m5\nLGNmoZ6pDUvVahmbfwy7+QIz27s8yw8jFnfJJdnXKzdk5NgjbruZS664JiPHBqhXa6eMHRvg5huv\n55q/XJ+x40vles5vI9OxZ1o2x5/p2KtXVfknTMl2PvDCUNv+9N492y1f0kNAP2C5mR1QaPmFJB9z\n2wK8bGZ/DpZfCZwZLL/YzMaXVG4sapjOOQdA+r/AHwbuAR77+ZDqCRwHtDWzLfkvREhqBZwEtCL5\n2uxESc2shFqkt2E65+JDOeGmYpjZVJK9dxV2HnCrmW0JtlkZLB8AjDSzLWb2NcmerzqVFF6lT5id\nu3SPOoS0dO/RM+oQUpbNsUN2x5+1sUvhprJpDnRXcuSC1yUdHCxvxLYd1ywJlhWr0l+SH9rVE2ZU\nsjl2yO74szb2zAwYUAWobWadJXUERgH7pnog55yLh2Jqj1t/WEjih0XbXRfCIuB5ADObJWmrpD1I\n1ij3KrRdXrCsWJX+ktw5l0WKabPM3XVvqjbuVjCVdhS27QnrBeBwSPZKBVQzs1XAi8AgSdUk7QM0\nBWYWPVhhXsN0zsVHmnfJJT0J9AT2kLQQuA74D/CwpI9I9jF7GiR735L0DD93kn1+SXfIwROmcy5O\nctIbwNPMiva5mu/UYra/Bbgl7PE9YTrn4iPmo0R7wnTOxUcG3zwrD54wnXPx4TVM55wLyROmc86F\nlOOX5M45F07Ma5jxjq6MLr/4XDq0akLf7h0Lln0y5yN+c3RP+vboxG+HDmTd2rURRhjeuWefxd55\nDeh0ULuoQ0nJ+HFjademJW1bN+fOO26LOpwyyebYIcvjz8y75OWmUiXMgSefyqPPvLjNsj//4Tyu\nvG44YyfPpM+x/Xngnr9HFF3ZnDbsDEa/NDbqMFKSSCS45OILePHlccz+YA6jRj7Fp/PmRR1WKNkc\nO2R//On2VpRplSphduzchV13222bZV99OZ+OnbsA0LVHL1596YUoQiuzw7p0pXbt2lGHkZJZM2fS\ntGkzmjRpQtWqVTlx0GDGjBkddVihZHPskP3x79A1TEkPSVou6cNMllOS5i1bMeHVlwB4+YXnWLa0\nxHfrXTlYunQJeXmNC+bzGuWxdEl2/NyzOXbI/vh39Brmw0CfDJdRotvveoDH/vMA/Y/swvr166la\nrVqU4TjnShLzGmZG75Kb2VRJTTJZRmn2bdqMx0eNAeCr+V8wacKrUYazQ2jYsBGLFi0smF+8ZDEN\nG5XYL2tsZHPskP3x+13yCmYGhTscWbXyWyDZGH7P32/llNN/F1VoZWZmxGGQurLq0LEj8+d/wYIF\nC9i0aRPPPj2Sfv36Rx1WKNkcO2R//OTkhpsiEpvnMEfcdnPB585duqfUU/pFZw9j+ltT+G7Nag5r\n14w/XHEt69b+yOMPPQASffsNYODJ2+20JHZOP/UUpkx5g9WrVtF8vyZc85frOW3YGVGHFUpubi4j\n7rqX447pTSKRYNgZZ9GyVauowwolm2OHzMU/ZfIbTJn8RvoBlibm75JnfJjd4JJ8TOEhL7ezTcaG\n2c20TA+zm2mZHGbXVV4ZG2b32HtCbfvTyxeWe/lhVEQNs2jvx845t307chtm0PvxNKC5pIWSsuOa\n0jkXjR38LnlxvR8759wvxbyGGZubPs45F/ebPp4wnXPxEfMaZryjc87tWNJswyzpdWxJl0lKSNq9\n0LIrJX0u6RNJvUsLzxOmcy42JIWaSrDd17El5QFHAQsKLWsFnAS0Ao4G7lMpB/eE6ZyLjXQTpplN\nBdZsZ9UI4E9Flg0ARprZFjP7Gvgc6FRSfJ4wnXPxoZBTWQ4p9QcWmdlHRVY1AhYVml8SLCuW3/Rx\nzsVGcbXHrSvmsfXbsneELKk6cBXJy/G0ecJ0zsVGTs72L3pzGrSmaoPWBfOb54buFHk/YG/gg6B9\nMg+YLakTyRrlXoW2zQuWFR9f2FKdcy7TyuGmDxS6cDezj82sgZnta2b7AIuBA81sBfAiMEhSNUn7\nAE2BmSUd2BOmcy4+0mzDDPE6tvFzMp0LPAPMBV4BzrdSeiPyS3LnXGyk23tWaa9jm9m+ReZvAW4J\ne3xPmM652Ih7d4OeMJ1zseEJ0znnQvKE6ZxzYcU7X3rCdM7Fh9cwnXMuJE+YzjkXkidM55wLK975\nMj4Js/6uO0cdQkpqd7wg6hDSsvjN/4s6hLTsXC036hBSlpsT8+wQAa9hOudcSMV1vhEXnjCdc7Hh\nNUznnAsr3vnSE6ZzLj68humccyF5wnTOuZA8YTrnXFjxzpeeMJ1z8eE1TOecC8kTpnPOheQJ0znn\nQop7woz3e0jOuR1L+qNGPiRpuaQPCy27XdInkt6X9JykWoXWXSnp82B979LC84TpnIuNchiX/GGg\nT5Fl44H9zaw98DlwZVBWa+AkoBVwNHCfSjm4J0znXGzk5CjUVBwzmwqsKbJsopklgtnpQF7wuT8w\n0sy2mNnXJJNppxLjS/F7OedcuSuHGmZpzgReCT43AhYVWrckWFasSp0wx48bS7s2LWnbujl33nFb\n1OH8wv3XDeHriX9l5tNXbrP8vME9eO+5a5j1zFXcdFH/bdY1blCbFVPv5KKhh1dkqGX2wH130+2Q\n9nQ7pD0P3n9P1OGEtmTxYo7pcwQd2reh00EHcN+9d0cdUpnF/bwvibT9acOiD1k97b8FU2rH1tXA\nZjN7KtX4Ku1d8kQiwSUXX8Ar416jYcOGdO3ckeOOG0CLli2jDq3A46Onc/9Tk/n3TacVLOt2cDOO\n6d6GDif9la1bE+yx2y7b7HPrpb9m3NQ5FR1qmcz7ZA5PPPYwE6fMoEqVKgz6TT969z2WvffZN+rQ\nSlWlShVuvf1vHNCuPWvXrqVb5w4ccWTvWJ03JcmG874kxdUed2nSjl2atCuYXz3tibIe93TgGKBw\nTWMJ0LjQfF6wrFiVtoY5a+ZMmjZtRpMmTahatSonDhrMmDGjow5rG9Pe/5Lvfly/zbKzB3blzocn\nsHVrssll1XfrCtb169mWrxavYu6X31RonGX12afzOKhDJ3baaSdyc3M5tEs3XnrxhajDCqV+gwYc\n0K49ADVr1qRFy1YsXVri/6FYyYbzviTF1TCLTqUdhkL30iX1Bf4E9DezjYW2exEYLKmapH2ApsDM\nkg6c0YQpKU/SJElzJH0k6aJMllfY0qVLyMv7+ZdHXqM8li6J/4nftEk9uh7UlMmPXsbYBy/ioNZ7\nAVBj52pcOuxIhj/4Cor5C7etWu3P9Glv8d2aNaxfv56J415l6ZJFpe8YMwu+/poPP3yfjp0OiTqU\n0LL1vM+X7k0fSU8C04DmkhZKOgO4B6gJTJA0W9J9AGY2F3gGmEuyXfN8M7OS4sv0JfkW4FIze19S\nTeBdSePNbF6Gy81aVXJzqV2rOj2G/Y2DW+/Ff287k9bHXc815x7DPU+8zoafNgOhfstGplmLllx0\nyR85YUBfdtmlJm3btScnJ7vG3lm7di1DTx7I7Xf+HzVr1ow6nB1Guue1mQ3ZzuKHS9j+FuCWsMfP\naMI0s2XAsuDzWkmfkLwLlfGE2bBhIxYtWlgwv3jJYho2KvEGWCwsXr6GFyZ9AMC7cxeyNZFg9113\noWPbvTn+iPYMv/h4dqtVg61bE2z4aTMPjnoz4oi3b8ippzPk1NMBGH7DtTTMyyt5hxjZsmULQwcP\nZPCQofTrPyDqcMokW8/7fHF/06fCbvpI2htoD8yoiPI6dOzI/PlfsGDBAvbcc0+efXokj/435Ztj\nGbTtYxJjXv+Qnh2bM/XdL2i6Vz2qVa3C6u/XcdRZP4/ueNXZR7N2/cbYJkuAld9+S526dVm8aCEv\njxnNuElTow4ptPPOPouWrVrx+wsvjjqUMsue8377Yp4vKyZhBpfjzwIXm9naiigzNzeXEXfdy3HH\n9CaRSDDsjOR/gjh55K+n071DM3bftQafvXIjN/3zFR4d/TYPXj+UWc9cxcbNWzjr2seiDjMlpw89\nie/WrKFq1SrcPuIeflWrVuk7xcDb097i6aeeYP82bTms00FI4vobh3NUn75RhxZKNpz3JYl7DVOl\ntHGmX4BUBXgJeNXM7ipmG7v62usK5rv36En3Hj0zGld58XHJo+XjkleMKZPfYMrkNwrmh990A2ZW\nrl9Akh3wl4mhtv3wxiPLvfwwKiJhPgasNLNLS9jGNmzObByZ4gkzWp4wo1G9qjKSMNtdFy5hfnBD\nNAkz048VdQFOAQ6X9F5wSz87rm2ccxWuAl6NTEum75K/BWRvFcA5V6FKesYyDirtq5HOuewT83s+\nnjCdc/ER97vknjCdc7ER83zpCdM5Fx9ew3TOuZBini89YTrn4sNrmM45F1LM86UnTOdcfHgN0znn\nQop5vvSE6ZyLD69hOudcSJ4wnXMuJH+X3DnnQop5BbPyDrPrnMs+6XbvJukhScslfVhoWW1J4yV9\nKmmcpF0LrbtS0ueSPpHUu7T4PGE652KjHMYlfxjoU2TZn4GJZtYCmARcmSxLrYGTgFbA0cB9KqUR\n1ROmcy42cqRQU3HMbCqwpsjiAcCjwedHgeODz/2BkWa2xcy+Bj4HOpUYXwrfyTnnMqIcapjbU8/M\nlkPB0N/1guWNgEWFtlsSLCuW3/RxzsVGcVfEqz97l9Wfzy6vYlIeQMwTpnMuNop7qqhOi4Op0+Lg\ngvkvX3moLIddLqm+mS2X1ABYESxfAjQutF1esKxYnjDT9NozN0UdQlqmf70q6hDS0q1p3ahDSFk2\njxqZKeX04LqCKd+LwOnAbcAwYHSh5U9IGkHyUrwpMLOkAxebMCXVKmlHM/uhtKidc64s0s2Xkp4E\negJ7SFoIXAfcCoySdCawgOSdccxsrqRngLnAZuB8K2Xc8ZJqmHNIXusX/gr58wbslcoXcs654oj0\nMqaZDSlm1ZHFbH8LcEvY4xebMM2scXHrnHMuE+LeShHqsSJJgyVdFXzOk3Rwafs451xZpfumT6aV\nmjAl3Qv0Ak4NFq0H/pnJoJxzO6bcHIWaohLmLvlhZnaQpPcAzGy1pGoZjss5twOKe+cbYRLmZkk5\nBA97StoDSGQ0KufcDinu/WGGacP8B/AcUFfSDcBUks8zOedcucrQq5HlptQappk9Juldfr4tP9DM\nPs5sWM65HVFJHWvEQdg3fXJJPthpeIcdzrkMiXe6DHeX/GrgKaAhyXctn5R0ZaYDc87teOL+WFGY\nGuZpwIFmth5A0nDgPcrwdLxzzoUR9wfXwyTMb4psVyVY5pxz5Srud8lL6nxjBMk2y9XAHEnjgvne\nwKyKCc85tyOJeb4ssYaZfyd8DvByoeXTMxeOc25HlrU1TDMrUw+dzjmXrri3YYa5S76fpJGSPpT0\nWf5UEcGla/y4sbRr05K2rZtz5x3Z8ax9IpHg9AE9uPzcZC9Vr48dzdBjD6Nbyzp8OueDiKMr2Zl9\nOnDBCYdz0cAjueTkvgCs/f47rj17EOcc14VrzxnMuh/j341q2xb70qXTgXTtfDC9unaOOpwyy8bz\nPl/c75KHeabyEZJDV4rkUJTPAE9nMKZykUgkuOTiC3jx5XHM/mAOo0Y+xafz5kUdVqmeefSf7NOs\nZcH8vs1bc8s/Hqd9py4RRhWOlMOt/3meu0dNZMRTYwEY9dA9tOvcjQfGvEW7Tl0Y9e+7I46ydMrJ\n4aVxk5g6/V1en5pdLVDZet7ny5VCTVEJkzBrmNk4ADObb2bXkEycsTZr5kyaNm1GkyZNqFq1KicO\nGsyYMaNL3zFCK5Yt4e3JEzhu4KkFy5rs24zGe+9HKR1Bx4SRsG27GZjx+jiO6D8IgCMGDGL6pLFR\nBFYmZoYlsrO7hGw87wuL+6uRYRLmxqDzjfmSzpV0HPCrMAeXtJOkGZLek/SRpOvSirYMli5dQl7e\nz30g5zXKY+mSEsc3itzdf72a319+Y+wbvosnrj17EJcM7sO4554AYM2qb6ldJznuTu069fhu9coo\nAwxFEgP69aFnl0N45D//ijqcMsnG876wuF+Sh3kO8xJgF+AiYDiwK3BmmIOb2UZJvcxsvaRc4C1J\nr5pZiQMN7YimvT6e2nvUo3nrtsyeMRWyoka5rTseH8Pudevz/eqVXHvOYBrtvd8vTu5s+GUwftKb\nNNhzT1Z++y3H9+tDixatOLRL16jD2iHE/fQI0/nGjODjj/zciXBo+W8IATsF5VVIJmjYsBGLFi0s\nmF+8ZDENG5U4RnukPpw9g7cmvcr0yRPYuPEn1q9by01/Oo9r77g/6tBC271ufQB23b0OnQ/vy2cf\nv8due9RlzcpkLXPNyhXsunudiKMsXYM99wSgTt269Ot/PO++MytrEma2nfdFxb3zjWIvySX9T9Lz\nxU1hC5CUE3Q+vAyYYGYV8tB7h44dmT//CxYsWMCmTZt49umR9OvXvyKKTsm5l13L85M/YtSk97hh\nxL85qHO3XyTLOLdj/rRhPRvWr0t+Xr+O96ZNZu9mrTikZ29eGz0SgNdGP03nXn2iDLNU69evZ+3a\ntQCsW7eOSRMn0Gr//SOOKrxsO++LSrcNU9Ilkj4Onup5QlI1SbUljZf0qaRxknZNNb6Sapj3pnrQ\nwswsARwYDNv7gqTWZja36HY333h9wefuPXrSvUfPtMrNzc1lxF33ctwxvUkkEgw74yxatmqV1jGj\nMGXCy4y46Qq+W7Oay885mWYt2/C3h0ZFHdYvfLfqW4b/4UwksXXLFnoeewIHHdaTZvu349bLzmbC\nCyOpt2ceV9z5YNShlmjFiuUMHXQCBN9j4KAhHHFk76jDCi1T5/2UyW8wZfIb6QdYinSabCQ1BC4E\nWprZJklPAycDrYGJZna7pCuAK4E/p1RGRdZaJF0LrDOzvxdZbhs2x7f2VJLZX62JOoS0rNm4KeoQ\n0tKtad2oQ0hZtSrZ21Ni9arCzMr1+lmSXfD8L+pS23Xvb1r/ovwgYb4NtCfZhPg8cDfJyl8PM1su\nqQHwhpm1LHrMMDL6LyapTn71V1J14Cggex4Kc85VqHTukpvZUuBvwEJgCfC9mU0E6pvZ8mCbZUC9\nVOML24FwqvYEHg0eS8oBnjazVzJcpnMuSxX3auTij2ay+OOSH66RtBswAGgCfA+MknQKv7zRnPLl\nbOiEKWknM9tYloOb2UfAQWWOyjm3QyouYe51QCf2OqBTwfyMp/+xvc2OBL40s9WQvHENHAYsl1S/\n0CX5ipTjK20DSZ0kfQR8Hsy3k3RPqgU651xx0nxwfSHQWdLOSm50BDAXeBE4PdhmGJDyq09haph3\nA/2AFwDM7ANJvVIt0DnnipNOb0VmNlPSsyRHhNgc/P0gyTcTn5F0JrAAOCnVMsIkzBwzW1Akq29N\ntUDnnCtObpr9u5nZDcANRRav5udRb9MSJmEuktQJsOD1xguBrOjezTmXXeL+oFWYhHkeycvyvYDl\nwMRgmXPOlauYvxkZ6l3yFcDgCojFObeDi/u75KUmTEn/YjvPLZnZ2RmJyDm3w4p5vgx1ST6x0Oed\ngV8DizITjnNuRxb3MX3CXJJvMxyFpMeBqRmLyDm3w8r6S/Lt2AeoX96BOOdczPNlqDbMNfzchplD\n8pmmlLpGcs65kmT1JXnwelE7kj1/ACQszr3YOueymoh3xizxOdEgOb5iZluDyZOlcy5jchRuiiy+\nENu8L+nAjEfinNvhxT1hFntJLqmKmW0BDgRmSZoPrANEsvLp3bY558pV3EcVLakNcybJviyzZwQl\n51xWy435y+QlJUwBmNn8CorFObeDy+bnMOtKurS4lUUHMnPOuXRl82NFuUBNiPl9fudcpRHzCmaJ\nCfMbM7uxwiLJUm0apzwmfCysWpvdw+x+sWxt1CGkrHVerahDiJ2cmNfPSm3DdM65ipLNNcwjKiwK\n55wji9sw84eqdM65ihL3u+Qxf+rJObcjkcJNxe+vXSWNkvSJpDmSDpFUW9J4SZ9KGicp5RsPnjCd\nc7GRI4WaSnAXyf4vWpHsOGgeyd7VJppZC2AScGXK8aW6o3POlbd0apiSagHdzOxhADPbYmbfAwOA\nR4PNHgWOTzU+T5jOudjICTkVYx9gpaSHJc2W9KCkGkB9M1sOYGbLgHqpxpdKj+vOOZcRxXW+8cm7\nbzPv3bdL270Kyf4vfm9m70gaQfJyvGi3lCl3U+kJ0zkXG7nFJMw2HQ6jTYfDCuZH/+v/trfZYmCR\nmb0TzD9HMmEul1TfzJZLagCsSDU+vyR3zsWGQk7bE1x2L5LUPFh0BDAHeBE4PVg2DBidanxew3TO\nxUY5PIZ5EfCEpKrAl8AZJPvFeEbSmcAC4KRUD+4J0zkXG+l2IGxmHwAdt7PqyLQOHPCE6ZyLjbi3\nEXrCdM7FRjYPUeGccxUq3uky/jXgtIwfN5Z2bVrStnVz7rzjtqjDKZO2LfalS6cD6dr5YHp17Rx1\nOKX6ZuliTvl1X/p0PYi+3TvwyIP/AOD779Zw2sB+HNH5AIYNPI4ffvg+4kh/adPGjZx2/OEMObYr\nJ/U9lAfvuhWAB++6laMPbcWQft0Y0q8b0yZPjDjScLL5vJcUaoosvjgMNS7JNmwu3zgSiQRtWzfn\nlXGv0bBhQ7p27shjT4ykRcuW5VrOpi2Jcj1evgNaNWXytFnUrl07I8fPV14dCH+7fBnfrlhO67bt\nWLd2Lf2PPIwHHx/FqKceo3bt3Tnnwsv459138v1333HFX24ulzIB1pRT/Bs2rKd69Rps3bqVM0/s\nzZ+uu51pkydQY5eaDP3tBeVSRlGZ6EC4os776lWFmZVr5pJkz72/NNS2J7RvWO7lh1Fpa5izZs6k\nadNmNGnShKpVq3LioMGMGZPy41cVzsywRGaScSbUrd+A1m3bAbBLzZo0bd6Cb5YuYeKrL/GbQUMB\nOGHQUCa8OibKMItVvXoNADZt2sjWrVsKHm+JQ4WiLLL9vI97DbNCEqaknODdzhcrojyApUuXkJfX\nuGA+r1EeS5csqaji0yaJAf360LPLITzyn39FHU6ZLF64gLkff8iBB3di5bcrqFuvPpBMqqtWfhtx\ndNuXSCQYcmxX+nRqziFde7F/u4MBeOaxBzn5mK7ceMUF/BjD5oSisv68DzlFpaJqmBcDcyuorEph\n/KQ3efPtd3j2hZf49wP38/ZbU6MOKZR1a9dy/plD+MvwO9mlZs1f1Abiehc0JyeHJ1+eyivT5jLn\ng3f58vN5DBz6W16c8iFPvTKVOnXrM2L4VVGHWeml2x9mpmU8YUrKA44B/p3psgpr2LARixYtLJhf\nvGQxDRs1qsgQ0tJgzz0BqFO3Lv36H8+778yKOKLSbdmyhd+fOYRfDzyZo44+DoA6devx7YrlQLKd\nc486daP2Q464AAAQTUlEQVQMsVQ1f1WLgw9J3uCpvUedggT/68HDmPPBexFHV7psP+9zpVBTVCqi\nhjkC+BNp9BCSig4dOzJ//hcsWLCATZs28ezTI+nXr39FhpCy9evXs3ZtcjTEdevWMWniBFrtv3/E\nUZXuiovPoWmLlpxxzs83SY7oeyzPjXwcgOee/i9H9u0XVXjFWrN6VcHl9k8/bWDG1NfZe7/mrPx2\necE2k8aNYb8WraIKMbRsPu8BFPJPVDL6HKakY4HlZva+pJ5UYPNDbm4uI+66l+OO6U0ikWDYGWfR\nslX8T3iAFSuWM3TQCSCxdcsWBg4awhFH9o46rBK9M2Mao58dSYtWbejXqzOS+OPVN3DuhZdxwW+H\nMurJx2jUeC/u/fd/ow71F1auWMZ1fzwXSxiJRILe/X5N1169+cul5/Dp3I/Iyclhz7y9uHr4dnvI\niZVsPu8h/qNGZvSxIkl/BYYCW4DqwK+A583stCLb2dXXXlcw371HT7r36JmxuMpTph4rqijZPi55\neT1WFIVsGpd8yuQ3mDL5jYL54TfdkJHHil79OFzPa0e3qRfJY0UV9hympB7AZWb2i+uDTDyHWVE8\nYUbLE2Y0MvUc5tg54RJm3/2jSZj+aqRzLjbifkleYQnTzCYDkyuqPOdc9onyhk4YXsN0zsVGTrzz\npSdM51x8eA3TOedC8jZM55wLyWuYzjkXUtzbMCtt927OuexTHq9GFu0dTVJtSeMlfSppnKRdU43P\nE6ZzLjZyFG4qRdHe0f4MTDSzFsAk4MqU40t1R+ecK285UqipOMX0jjYAeDT4/ChwfMrxpbqjc86V\nt3LoQHh7vaPVN7PlAGa2DKiXanx+08c5Fx/FZMPZ06cye0bJnWhvp3e04qTccUWlHQStonjnG9Hy\nzjeikanON6Z/8V2obTs33e0X5RfTO9r/gA5ATzNbLqkB8LqZpdTnnV+SO+diI50hKszsKjPby8z2\nBQYDk8zsVGAMcHqw2TAg5VHh/JLcORcbGXoM81bgGUlnAguAk1I9kCdM51x8lFPGLNw7mpmtBo4s\nj+N6wnTOxYa/GumccyF55xvOORdSzPOlJ0znXIzEPGN6wnTOxYa3YVZy1apk96OsdWpWizqEtGTz\nz3/L1ux+6SET4t69mydM51x8eMJ0zrlw/JLcOedC8seKnHMupJjnS0+YzrkYiXnG9ITpnIsNb8N0\nzrmQvA3TOedCinm+9ITpnIuRmGdMT5jOudjwNkznnAvJ2zCdcy6kmOdLT5jOufhQzKuYnjCdc7ER\n83zpw+w65+JDIaft7ivlSZokaY6kjyRdFCyvLWm8pE8ljZO0a6rxecJ0zsVHOhkTtgCXmtn+wKHA\n7yW1BP4MTDSzFsAk4MpUw6vUCXP8uLG0a9OStq2bc+cdt0UdTplkc+z5EokE3Q7twKATB0QdSqku\nu/Ac2jdvzJFdDi5Y9vfbbqbD/vvSt8ch9O1xCK9PHBdhhOFs3LiRXt0OpcshB3PIwe245eYbow6p\nTBTyz/aY2TIzez/4vBb4BMgDBgCPBps9ChyfanyVNmEmEgkuufgCXnx5HLM/mMOokU/x6bx5UYcV\nSjbHXth9995Ni5atog4jlEFDTuOJ5176xfKzz7+IsZNnMHbyDHod2SeCyMpmp5124uVxr/HWjHeZ\nNnM248eP5Z1ZM6MOKzQp3FT6cbQ30B6YDtQ3s+WQTKpAvVTjq7Q3fWbNnEnTps1o0qQJACcOGsyY\nMaNp0bJlxJGVLptjz7dk8WImjHuFP15xFffePSLqcErV6dAuLF644BfLzSyCaNJTo0YNIFnb3Lpl\nS+zvPBdWXKTT35rC9LemhDuGVBN4FrjYzNZKKvqPmPI/asYTpqSvge+BBLDZzDplukyApUuXkJfX\nuGA+r1Ees7LkN202x57vyssv5aa/3s4PP3wfdShpeeRf9/Pc009ywIEH85ebbqPWrinfL6gwyaaQ\njnz15Xx+d875HNyhY9QhhVdMxuzctTudu3YvmL/rjuHb312qQjJZPm5mo4PFyyXVN7PlkhoAK1IN\nryIuyRNATzM7sKKSpYvW2Fdfpm69+hzQrj1mlpW1NIBhZ53DtPc/Zfybs6hXrz43XHN51CGFkpOT\nw1sz3mXe/IW8M2sm8z6ZG3VIoaXThhn4DzDXzO4qtOxF4PTg8zBgdNGdwqqIhKkKKmcbDRs2YtGi\nhQXzi5cspmGjRhUdRkqyOXaAGW9P49WXx3BAq6acOewU3pz8BmefNSzqsMpsjzp1Cy5nh5x2Jh/M\nfifiiMqmVq1adO/Rkwnj43+zKl86bZiSugCnAIdLek/SbEl9gduAoyR9ChwB3JpqfBWRyAyYIGmW\npN9VQHkAdOjYkfnzv2DBggVs2rSJZ58eSb9+/Suq+LRkc+wA1904nLmff82Hn3zBw489SfeevXjw\noUdL3zFixra14RXLlxV8fvWlF2jRav8owiqTlStX8v33yWaQDRs2MOm1iTRv0SLiqMJL56kiM3vL\nzHLNrH1wRXuQmY01s9VmdqSZtTCz3mb2XarxVcRNny5m9o2kuiQT5ydmNrXoRjffeH3B5+49etK9\nR8+0Cs3NzWXEXfdy3DG9SSQSDDvjLFq2yo47ttkce7b6/W9PY/pbU1izehWd2jTlsiuvZdqbk5nz\n0Qfk5OTQeK8m3DriH1GHWarly77hnN+eQSKRIJFIcMKJJ9Gn7zFpH/fNyW/w5pTJ5RBhyeJ+f0oV\n2b4k6TrgRzP7e5HltmFzdrZzZbvNWxJRh5CWH37aEnUIKdu1evY+pPKrnXMxs3JNb5Js0eqNobZt\nvPtO5V5+GBm9JJdUI7jFj6RdgN7Ax5ks0zmXvXIUbopKpn/F1Qf+FzwHVQV4wszGZ7hM51yWivsl\neUYTppl9RfJpe+ecK5X3uO6cc2HFO196wnTOxUfM86UnTOdcfOzQbZjOOVcW3obpnHNhxTtfesJ0\nzsVHzPOlJ0znXHx4G6ZzzoXkbZjOORdS3GuYlXZMH+ecK29ew3TOxUZOzKuYnjCdc7ER83zpCdM5\nFx8xz5eeMJ1zMRLzjOkJ0zkXG3F/rKjS3yWfMvmNqENISzbH/+aUN6IOIS3TpmZ+DJtMeTNLz5t0\nRo1M7q++kuZJ+kzSFeUdnyfMmMvm+Cti0KxMenvqlKhDSFm2/uzTGTVSUg5wL9AH2B84WVLL8oyv\n0idM51wWSSdjQifgczNbYGabgZHAgPIMzxOmcy42FPJPMRoBiwrNLw6WlV98FTnMbrFBJAdJc85l\nkQwMs/s10CTk5svNrEGR/U8A+pjZ2cH8UKCTmV1UXjHG4i55FOMLO+fixcz2TvMQS4C9Cs3nBcvK\njV+SO+cqi1lAU0lNJFUDBgMvlmcBsahhOudcusxsq6QLgPEkK4MPmdkn5VlGLNownXMuG/gluXPb\nIcW9GwgXhUqbMCXlRh1DKiQ1ldRB0k5Rx5IKSftL6iFpj6hjKStJXSWdCmBmlm1JU9Jxki6OOo7K\nrNK1YUpqbmafBe0ZuWa2NeqYwpLUD/grsApYJuk6M/ss4rBCk3Q0cBvwJVBV0llmtizisEoVvCFS\nA3ggOatdzOyfQdLMMbNExCGWSlJv4CbgT1HHUplVqhpmkHDel/QkFDQCZ0VNU9JhwB3AMDPrBawB\n/hxtVOFJ6gncBfzWzI4HNgFtIg0qJDNLmNla4FHgIeAwSZfkr4s0uBCCc+dx4GwzmyBp1+BOcY2o\nY6tsKk3ClLQLcAHwB2CTpP9CdiVN4DYzey/4fB2wexZdmi8HzjGzmZIaAIcAF0h6QNKJWXJ5uwVo\nTDJxdpL0d0m3KCnO/1dWAZuBPYOmkBeA+4FHsuhnnxXifBKUiZmtA84EngT+COxcOGlGGVtIM4Dn\noaD9dSeSbz3UCpbFuk3QzD4xs9eD2bOA+4Ka5tvAiUCdyIILbzSwzMxeA94BzgVqWVJsa5pm9ilw\nLDAC+Ijk/4F+wFjgBKB2dNFVLpUmYQKY2VIzW2tmK4FzgOr5SVPSQeXdc0l5MrOtZvZDMCvgO2C1\nmX0r6RTgZknVo4swPDMbbmY3B58fIZn0G0caVDgbgBaSfkcyWd4K7CXpnGjDKp2ZfUAySQ43s38F\nzQz/IZks9yp5bxdWpbvpk8/MVgUn+h2S5gG5QK+IwwrFzLYAayUtknQL0Bs43cw2RBxaqSTJCj3c\nG7zfWx9YGl1U4ZjZUkmLgGuB35vZGEm9gC8iDi0UM5sLzM2fD372dYFvIguqkqn0D64HjfdXAEeZ\n2UdRxxNG0OZUFfgk+PsIM/s82qjKJmh7HQpcCgwys48jDikUSY2Bemb2bjCfFXfJCwvOnzNINk0N\nNLM5EYdUaVTqhCmpNvAMcJmZfRh1PGUl6XRgVjae8JKqAkcB84M2tqxStKacTYKE2YNke+y8qOOp\nTCp1wgSQtLOZ/RR1HKnI5v+0zlVGlT5hOudcealUd8mdcy6TPGE651xInjCdcy4kT5jOOReSJ8xK\nRNJWSbMlfSTpaUk7p3GsHpLGBJ+Pk3R5CdvuKum8FMq4TtKlYZcX2eZhSb8pQ1lNJGXFc7guvjxh\nVi7rzOwgM2tLsjOGc4tuUMaOGAzAzMaY2e0lbFcbOL9MkUbDHwlxafGEWXm9yc8DQs2T9GhQw8qT\ndJSkaZLeCWqiNQAk9ZX0iaR3gILam6Rhku4JPteT9Lyk9yW9J6kzcAuwX1C7vS3Y7o+SZgbbXVfo\nWFdL+lTSFKBFaV9C0m+D47wnaVSRWvNRkmYF3+/YYPscSbdLmhGU/bu0f5LOBTxhVi4CkFQFOJpk\nzzUAzYB7g5rneuAakq9bdgDeBS4NXmV8EDg2WN6gyLHza2d3A2+YWXvgIGAOyX47vwhqt1dIOgpo\nZmadgAOBDkr2Zn4QcBJwAMnedTqG+E7PmVknMzsQmEeyJ6R8TcysI8lOJ/6p5EiBZwHfmdkhQCfg\nbElhx7p2rkSVtvONHVR1SbODz2+S7Ay3EfC1mc0KlncGWgNvFXpn/W2gJfClmX0ZbPdfYHu1s8OB\ngmEcgB8l7V5km94ka3+zSSbxXUgm7VrA/8xsI7BRUpghUA+QdBOwW3CccYXWPRPE8YWk+cF36A20\nlTQw2KZWUHZWvYvv4skTZuWy3swOKrwgaLJcV3gRMN7MTimyXbtgXWnCtAMKuMXM/lWkjFTGm3kY\n6G9mH0saRvId6e3FomBewIVmNqFI2V7LdGnzS/LKpbiEV3j5dKCLpP0AJNWQ1Izk5W4TSfsE251c\nzLFeI7jBE7QX1gJ+BH5VaJtxwJlK9oKPpIaS6gJTgOMl7STpV8BxIb5TTZLjG1UFTimybqCS9gP2\nAT4Nyj4/aJZAUjP93I+o9zzu0uI1zMqluNpfwXIzWxn0gvRU0G5pwDVm9rmS/Ye+ImkdyUv6mts5\n1h+AByWdRXJIh/PMbEZwE+lD4NWgHbMV8HZQw/0RGGpm70l6BviQ5JAWM0N8p78E260g2St94cS8\nMFj3K5LDY2yS9G9gb2B20OSwAji+lJ+Pc6F45xvOOReSX5I751xInjCdcy4kT5jOOReSJ0znnAvJ\nE6ZzzoXkCdM550LyhOmccyF5wnTOuZD+H0jDH0a9pUWoAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25d7b4045f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#From scikit's user guide\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(dev_set.KIScore, predicted)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Graded answers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Cross validation for checking final classifier\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "# Get sizes of training and test sets\n",
    "rows, columns = df.shape\n",
    "\n",
    "kf = KFold(rows, 10, shuffle=True)\n",
    "avg_accuracy = 0\n",
    "count = 1\n",
    "#for train_indices, test_indices in kf:\n",
    "    #train_set = df.loc[train_indices] \n",
    "    #dev_set = df.loc[test_indices] \n",
    "    \n",
    "    #pipeline_p = pipeline2.fit(train_set['Answer'], train_set.KIScore)\n",
    "    \n",
    "    #trial_predictions = pipeline_p.predict(dev_set[\"Answer\"])\n",
    "    #accuracy = accuracy_score(dev_set.KIScore, trial_predictions)\n",
    "    #print(count,\": \",accuracy)\n",
    "    #avg_accuracy += accuracy_score(dev_set.KIScore, trial_predictions)\n",
    "    #count = count + 1\n",
    "#print(\"Average:\",(avg_accuracy/10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets break the answers by confidence.\n",
    "\n",
    "This was just something I was working with at the end. Considering that I had peaked in terms of accuracy across the set, I decided to implement something that would grade only those questions on which the classifier had the most confidence. For example, in the below code, the classifier only classifies answers if there is a certain category has at least a 0.8 probability of being correct. Once this is done, I see a higher accuracy rating. The though behind this was that I could with a very high accuracy predict at a large portion of the answers, but would leave some answers for manual grading in which the classification might turn out to be erroneous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probab = p_predictor.predict_proba(dev_set['Answer'].values)\n",
    "count = 0\n",
    "conf = pd.DataFrame()\n",
    "uncern = pd.DataFrame()\n",
    "for i in range(0, len(probab)):\n",
    "    filt = list(filter(lambda x: x > 0.68, probab[i]))\n",
    "    if len(filt) > 0:\n",
    "        df1 = pd.DataFrame([list(dev_set.ix[i])], columns = ['WISEID', 'Answer', 'KIScore'])\n",
    "        #print(df1)\n",
    "        conf = conf.append(df1)\n",
    "    else:\n",
    "        df1 = pd.DataFrame([list(dev_set.ix[i])], columns = ['WISEID', 'Answer', 'KIScore'])\n",
    "        uncern = uncern.append(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89743589743589747"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_ch = p_predictor.predict(conf['Answer'].values)\n",
    "accuracy_score(conf.KIScore, predicted_ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72860125260960329"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohen_kappa_score(conf.KIScore, predicted_ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[ 19   0   0   0]\n",
      " [  0 142   1   0]\n",
      " [  0  17  12   0]\n",
      " [  0   1   1   2]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUwAAAEpCAYAAAD4Vxu2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl8FeW9x/HPNyFSlaK4IqBxQdw3Cmi1ZbFuVaRe624V\nl9bt2lL1ti7VutTWtXqt1rbX9qptVXBH1IpaG70oCgpuKC5YkN1W0KpYQfO7f5xJPESSDGfJmSTf\nN695cWbmmZnfkMMvzzwz8zyKCMzMrHVVlQ7AzKy9cMI0M0vJCdPMLCUnTDOzlJwwzcxScsI0M0vJ\nCdOQ9HdJu7f1tmbtjRNmxkk6TNLTkj6UtEDSREknVzous87ICTPDJJ0BXA1cBqwfET2Bk4BdJdU0\ns41/pitJUnWlY7D2wf+5MkpSd+BC4OSIuCciPgKIiBci4qiIWJaUu1HS9ZIekPQBMFTSvpKmSHpf\n0ixJ5zfZ91GSZkr6h6RzmqyTpLMkvZmsHy1pzTTbruAcmo1DUq2keklHJ+veyd+fpIGSJifbzpd0\nZbL8JkmnJZ97Jfs4OZnfTNK7efsYLmmqpMWSJkjaLm/d3yX9WNILwIeSqiSdKWmOpH9JelXSsLQ/\nL+skIsJTBidgb2ApUNVKuRuBxcAuyfwqwGBgm2R+W2A+MCKZ3xr4ANgNqAF+mRxn92T9KOApYINk\n/W+AW9Nsu4LYWoqjFqgHfpfEvD3wb2CLZP1TwJHJ59WAQcnnY4GxyefDgTeA2/LW3ZN83glYCAwA\nBBwF/B2oSdb/HZgC9AK6Av2At8nV5AE2Ajap9PfAU7Ym1zCzax3gnxFR37BA0pNJbWmJpK/llR0b\nEU8DRMTSiHgiIqYl8y8Do4EhSdlvA+Mi4snI1VLPA/I7FDgR+ElEzE/WXwQclFzqt7btclqJg2Tb\nC5KYXwReAHZI1i0F+kpaOyKWRMSkZPnjQMO5DwYuJ5fASfb9ePL5e8BvI+LZyPkT8AmwS97xr4mI\neRHxCfAZucS9raQuEfF2RPy9uXOzzskJM7veBdbJb5OMiN0iokeyLv9nNzt/Q0mDJD2WXOa+Ry4J\nrpOs7pVfPiKWJPtrUAvcI2mRpEXAK8AyYP0U2y6nlTgaLMz7vATolnw+HtgCmC7pGUn7Jcd8C/hI\n0k7A14H7gXmS+rF8wqwFzmg4D0mLgT7JOTSYk3cuM4AfAhcACyXdKmmD5s7NOicnzOyaSK5G9K0U\nZZvW8m4F7gV6R8Sa5C57laybD2zYUFDSasDaedu+DXwzItZKph4RsXpEzE+xbVMtxdHyCUXMiIgj\nImJdcrXIOyWtmqx+HDiI3OX1fOAJYCSwJvB8UmY28PMm59EtIsbkH6bJMUdHxNfJJVuAS9PEap2H\nE2ZGRcT75C6Hr5f0bUndkhsyO5Jr02tJN2BxRCyTNAg4Im/dncBwSQ132i9i+ST2O+AXkjYCkLSu\npBEpt12ZOGhpW0lHSmqojb5PLrk1NE88AZya/A1Ql8xPiIiGJHgDcFJyXCStntyEWr2Z4/WTNEzS\nKuSaAz7OO54Z4ISZaRFxBXA68GNgQTL9Jpl/qoVNTwF+Jul94FygsVYVEa8A/wncBswjd0k9J2/b\na4CxwMPJ9k8Bg1JumzqOhnBamN8HmCbpX+QerTo0aWuEXA2zG59ffk8AVs2bJyKeI9eOeV3StPA6\nuVpoc8fuSq5G+Y/k3NYFzm7h3KwT0ue/kM3MrCWuYZqZpeSEaWaWkhOmmVlKTphmZil1qXQAAJJ8\n58msnYmIVM/UpqVVugfLPkhbfFZEbFzK46eRibvkkuLNhUvKfpxrrriYUT86t+zHAei91qqtFyqB\niy+6gHN/ekGbHKutdLRzasvzqRbUtEHfS5JKnzCl+NJO309V9t9Try358dPIRA3TzAwAtXkOXClO\nmGaWHRnvzrVTJcyddx1c6RBKbvCQoZUOoeQ62jl1tPMpq4zXMDtVG2Zbaqs2TLN87b4Nc+AZqcr+\ne/Iv3YZpZp1cxmuY2W4wMLPORVXppuY2l/4gaaGkF/OWXSTphWS4kock9UyW1yadcU9JputbC88J\n08yyQ0o3Ne9GcsO75Ls8InaIiJ2AB4D8Ma7ejIj+yXRKa+H5ktzMsqOquAbYiJggqbbJsg/zZldn\n+X5OV6oNwAnTzLKjTI8VSboYOBp4D8gfDXRjSVPIdVJ9XkRMaGk/Tphmlh3NXG5/9t5M6t+fVfBu\nI+Jc4FxJZwLfJzd203xgo4hYLKk/cK+krZvUSJfjhGlm2dFMDbO6x6ZU99i0cf6z2U+ssFwKtwIP\nkoxWSm44EiJiiqQZ5IZbntLcxr7pY2bZUeRd8oa9kNc2Kalv3roDgFeT5Y2jskraFOgLvNXSjl3D\nNLPsqCruOUxJtwJDgbUlvU3ujvh+krYgN/b8LOCkpPhg4CJJS8ndCDoxIt5raf9OmGaWHUXe9ImI\npiOTQu5RoxWVvRu4e2X274RpZtmR8Td9nDDNLDvcW5GZWUoZr2FmO50X4awfnsTO22zMfkMHNS6b\nPu0lDt5vGMOH7cyJRx/MRx81+7hV5j08/iF22HZLttu6H1decVmlwykJn5OV6C552XTYhHnQ4Udz\n45ixyy075/RTOPOnP+f+vz3DXvuO4IbrrqpQdMWpr6/ntFGnct8D45nywjTuGH0br02fXumwiuJz\nMqAU75KXVYdNmAN23pU11uix3LKZf5/BgJ13BWDXwcN46IGxK9o08yZPmkTfvptTW1tLTU0NBx16\nGOPGtc9zaeBzMqBz1zBX1NVSJW2+xVY8+tD9ADx4390smDe3whEVZt68ufTps2HjfJ/efZg3t32e\nSwOfkwG5zjfSTJUKr8z7X1FXSxVz6X//lj/f+D/8x95f4+MlH1GzyiqVDsnM8mX8krysd8lX1NVS\nJW2y2ebcNOY+AGa+9SZ/e+ShCkdUmF69ejN79tuN83PmzqFX794VjKh4PicDMv9YUbajK1JEkD9m\n0bv//AeQa4z/9dWXccTI71YqtKIMGDiQGTPeZNasWSxdupQ7x4xm+PARlQ6rKD4nAzLfhpmZ5zCv\nueLixs877zqYXXYrboTH0046hmeeeoLFixfx9f79GPWjc/noww/5842/QxJ77TuCbx92VLFhV0R1\ndTVXX3Md+++7F/X19Yw89ni23GqrSodVFJ9TttXV1VFXV1f+A2X8OcyyjxqZXJKPi4jtWyjjUSPN\nSqDdjxo54repyv77vpM67KiRy3W1ZGbWrIzXMMv9WNGtwFNAP0lvSzq2nMczs3auM7dhNtPVkpnZ\nimW8hpmZmz5mZsp4wuzQjxWZWfsiKdXUwvZfeLtQ0uWSXpX0vKS7JHXPW3e2pDeS9Xu1Fp8Tppll\nh1JOzVvR24UPA9tExI7AG8DZAJK2Bg4BtgK+CVyvVqq4TphmlhnF1jCTccUXN1n2aETUJ7NPA32S\nzyOA0RHxaUTMJJdMB9ECt2GaWWZUVZW9DncccFvyuTcwMW/d3GRZs5wwzSwzynnTR9JPgGURcVur\nhZvhhGlm2dFMvvx04at8+s6rhe9WOgbYF9g9b/FcYMO8+T7JsmY5YZpZZjRXw6zpuTU1PbdunF/6\n8r0t7oa81CtpH+BHwOCI+CSv3H3ALZKuJncp3heY1NKOnTDNLDOKvSRP3i4cCqwt6W3gfOAcYBXg\nkWT/T0fEKRHxiqTbgVeAZcAp0UrnGk6YZpYZxSbMZt4uvLGF8pcAl6TdvxOmmWVG1t/0ccI0s+zI\ndr50wjSz7HAN08wsJSdMM7OUnDDNzNLKdr50wjSz7HAN08wspTbofKMoTphmlhmuYZqZpZXtfOmE\naWbZ4RpmSr3XWrXSIZRUj4GnVjqEkls06dpKh1BSWf/P2Rll/WeSmYRpZuaEaWaWVrbzpROmmWWH\na5hmZillPWFm+ylRM+tUih1mV9IfJC2U9GLesh6SHpb0mqTxktZIltdKWiJpSjJd31p8TphmlhnF\nJkxyvavv3WTZWcCjEbEF8Bhwdt66NyOifzKd0lp8Tphmlh1KOTUjIiYAi5ss/hZwc/L5ZuCAJkdM\nzQnTzDKjBDXMFVkvIhYCRMQCYL28dRsnl+N/k/S11nbkmz5mlhlVVW1y06dhZMj5wEYRsVhSf+Be\nSVtHxIfNbeiEaWaZ0VztccnbL/Lx7BdXuC6FhZLWj4iFknoC7wBExFJgafJ5iqQZQD9gSnM7csI0\ns8xo7mp79drtWb12+8b5xRNvaXE3LN82eR9wDHAZMBIYmzuW1gEWRUS9pE2BvsBbLe3YCdPMMqPY\n5zAl3QoMBdaW9DZwPnApcIek44BZwCFJ8cHARZKWAvXAiRHxXkv7d8I0s8wo9rn1iDiimVV7rKDs\n3cDdK7N/J0wzy4w2uulTMCdMM8uMjL8Z6YRpZtmR9XfJnTDNLDMyni+dMM0sO7Jew+wUr0Y+PP4h\ndth2S7bbuh9XXnFZpcNJ7TfnH8HMR3/BpDFnf2HdqKN256PnfkWP7qsBMGznLZhwy495ZsxZTPjz\njxg8YPO2DrcoJ51wPBv36cmg/jtUOpSSaq/fvUop06uRJdPhE2Z9fT2njTqV+x4Yz5QXpnHH6Nt4\nbfr0SoeVyp/GPs2IU379heW911uT3XfekrfnL2pc9s/FH/LtH/yGnQ+9lO/99E/878VHt2WoRTt6\n5LGMvf+hSodRUu35u1cpUrqpUjp8wpw8aRJ9+25ObW0tNTU1HHToYYwbN7bSYaXy1PNv8d4HS76w\n/PL/OpBz/vve5Za99PpcFr77AQCvvrWArqvU0KVL+/nx7rrb1+jRo0elwyip9vzdq5ROXcOU1EfS\nY5KmSXpJ0g/KebwVmTdvLn36bNg436d3H+bNndvWYZTMfkO2Y87C95j25rxmy/zHHjvy/PTZfPpp\nfRtGZk11tO9eW6iqUqqpUsp90+dT4PSIeF5SN+A5SQ9HhK9LCvClrjX8+Li92O/k6xqXNf1tu9Wm\nPbno+yPY76Trmm5ulnkZv+dT3hpmRCyIiOeTzx8CrwK9y3nMpnr16s3s2W83zs+ZO4devds0hJLZ\ntM86bNRrbSaNOZtX77+A3uv14Klbf8y6PboBubbN0b/8Hsef+8fl2jetMjrSd6+tZP2SvM0eK5K0\nMbAj8ExbHRNgwMCBzJjxJrNmzWKDDTbgzjGjufnPt7VlCEX6/Avyyoz5bLLnOY1rXr3/Ar56+GW8\n98HHdO/2Je761Umce81YJr00s0KxFiciiIjWC7YT7f+71/Y6dQ2zQXI5ficwqqXOOcuhurqaq6+5\njv333Yv+O2zDQYcexpZbbdWWIRTspl8cQ93NZ7B57bq8/uBFHDVil+XWR3x+SX7SoUPYtM86nH3C\nN5l425k8deuZrL3m6pUIuyDHHHUkw4bsxhtvvE6/zWr54803VjqkorXn716lZL2GqXL/RpfUBbgf\n+EtEXNNMmfjJeec3zg8eMpTBQ4aWNa5y6zHw1EqHUHKLJl1b6RBKKusPSReiWlBTXfr91tXVUVdX\n1zh/4YUXEhEl/QeUFDtfUtdqOYBnzh5a8uOn0RYJ84/APyPi9BbKxMfLOs6lGDhhtgdOmIWTVJaE\nuculj6cq+/RZQyqSMMv9WNFuwJHA7pKmJoMN7VPOY5pZ+5X1B9fLetMnIp4E2uD3nZl1BCXocX0U\n8N1k9oaI+JWkHsAYoBaYCRwSEe8Xsv/28yqImXV4xdQwJW0DHA8MIPdEznBJmwFnAY9GxBbAY8AX\nO2dIyQnTzDKjyLvkWwHPRMQnEfEZ8ARwIDACuDkpczNwQKHxOWGaWWYUmTBfBr4uqYek1YB9gQ2B\n9SNiIeRepgHWKzQ+94dpZplRzHviETFd0mXAI8CHwFTgsxUVLfQYTphmlhnNVR4XvzGF996c2ur2\nEXEjcGNuX/o5MBtYKGn9iFgoqSfwTqHxOWGaWWY0d7m9Vr+vsFa/rzTOzxr/v81tv25E/EPSRsB/\nALsAmwDHAJcBI4GC+9hzwjSzzCjBM5Z3SVoLWAacEhH/Si7Tb5d0HDALOKTQnTthmllmVBWZMSNi\n8AqWLQL2KGrHCSdMM8uMrL+t6oRpZpmR9ff7nTDNLDMqOPpEKk6YZpYZ7baGKal7SxtGxL9KH46Z\ndWYZz5ct1jCnkXsiPv8UGuYD2KiMcZlZJySynTGbTZgRsWFz68zMyiHrbZipOt+QdJikc5LPfSR9\npbVtzMxWVtbH9Gk1YUq6DhgGHJUsWgL8tpxBmVnnVF2lVFOlpLlLvmtE9Jc0FXJPzUtapcxxmVkn\n1J5v+jRYJqmKpEskSWsD9WWNysw6paw/VpSmDfPXwF3AupIuBCaQ6/XDzKyk2v0gaBHxR0nP8fnL\n6wdHxMvlDcvMOqNiO98ot7Rv+lST6y4p8LAWZlYm2U6XKRKmpJ8ARwD3kDufWyXdEhGXlDu49uzV\nR66sdAgl996SZZUOoaR6rO57l1mT9TbMNDXMo4GdImIJNHb7PhVwwjSzksr6g+tpEub8JuW6JMvM\nzEqqmBqmpH7AGD5/hXtT4DygB/A9Ph/L55yIeKiQY7TU+cbVyYEXAdMkjU/m9wImF3IwM7OWFHNF\nHhGvAzvl9qMqYA65psTjgKsi4qpi42uphtlwJ3wa8EDe8qeLPaiZ2YqUsA1zD2BGRMxO9lmSHbfU\n+cYfSnEAM7O0StiGeShwW978qZKOAp4FzoiI9wvZaZp3yTeTNFrSi5Jeb5gKOZiZWUtK0fmGpBpg\nBHBHsuh6YNOI2BFYABR8aZ7mps9NwMXAlcA3gWNJXpM0Myul6maS4fxpk5n/SupbJ98EnouIfwA0\n/J24ARhXaHxpEuZqETFe0pURMQM4V9Kz5O4+mZmVTHOVx17bDqTXtgMb56fe9ZuWdnM4eZfjknpG\nxIJk9kA+vz+z0tIkzE+SO04zJJ0EzAW+XOgBzcyaU+xNH0mrkbvhc0Le4ssl7Uiu06CZwImF7j9N\nwjwNWB34AfBzYA1yt+nNzEqq2JvkyQs26zZZdnRxe/1cms43nkk+fsDnnQibmZVcu+18Q9I9tHBz\nJyIOLEtEZtZpZTxftljDvK7NojAzox13vhERf23LQMzMst53ZNr+MM3Myq7d1jDNzNpaR+jeDQBJ\nXSPik3IGY2adW9YTZpp3yQdJegl4I5nfQdK1ZY/MzDqdUrxLXk5p2lh/BQwH3gWIiBeAYeUMqtQe\nHv8QO2y7Jdtt3Y8rr2ifA16eOeokBmxdyz5DPn897PvfO4rhu3+V4bt/la9/ZUuG7/7VCka48k4/\n9US233xDvrHrVxqX/eynZzN40Pbs8bWBfPeoQ/ngX/+qYITF6wjfvbZUpXRTxeJLUyYiZjVZ9lk5\ngimH+vp6Tht1Kvc9MJ4pL0zjjtG38dr06ZUOa6UddPhR/HHMfcstu/aGP3H/YxO5/7GJ7DP8APbe\n71sViq4whx55NLfedf9yy4bsvgd1Tz/PoxMms8lmfbn26ssrFF3xOsp3ry1VVynVVClpEuZsSYOA\nkFQt6YdAu+nebfKkSfTtuzm1tbXU1NRw0KGHMW7c2EqHtdIG7rIb3ddcs9n1D469ixEHHtKGERVv\n56/uxppNzmnw0G9QVZX7WvYfMIj5c+dWIrSS6CjfvbZUlXKqlDTHPhk4HdgIWAjskixrlaSukp6R\nNFXSS5LOLzzUwsybN5c+fTZsnO/Tuw/z2vF/whWZNHEC66y3PrWbbFrpUEpq9J9vZtiee1c6jIJ1\nhu9eqUnppkpJ8y75O8Bhhew8Ij6RNCwilkiqBp6U9JeImFTI/mzFxt1zR7urXbbmmisvpaamhgMP\nLuirZ+1Uu32XvIGkG1jBO+URccIKin9Bw/C8QNfkeG3a+XCvXr2ZPfvtxvk5c+fQq3fvtgyhrD77\n7DMeun8s9z/2VKVDKZkxt/yRvz7yEHfcN77SoRSlo3/3yiHj+TLVJfmjwF+T6UlgPSD185iSqiRN\nJdc1/CMR0aYjTg4YOJAZM95k1qxZLF26lDvHjGb48BFtGULpBBDL/76ZUPdX+vbbgvV79qpMTEWK\nCCLvd+jfHh3Pb669iptuu4uuXbtWMLLidajvXhvJ+l3yNJfkY/LnJf0JmJD2ABFRD+wkqTtwr6St\nI+KVlY60QNXV1Vx9zXXsv+9e1NfXM/LY49lyq63a6vAlM+rEkTz95BO8t3gRu+24OT/88XkcfMTR\n3H/vnezfTi/HT/nu0Uyc8ASLF73LgG378l9nnce1V13G0qXLOOyAfQH4ysBBXPLL9vnYb0f57rWl\nrF+SK2LlrpAlbQY8HBGbrfTBpPOAj5qODywpfnLe5/eDBg8ZyuAhQ1d295my4L1/VzqEkutak/Wu\nEVZOj9VXqXQIJVctqKku/X7r6uqoq6trnL/wwguJiJJmN0lx0SNvpCr70z03X+HxJa0B/B7YllwP\n68eRe6pnDFBLrsf1QwodNbLVhClpMZ+3O1YBi4CzIuL2VncurQMsi4j3Ja0KjAcujYgHm5SLj5d1\nrHHVnDCzzwmzcJLKkjAvfjRdwjx3j2YT5k3A4xFxo6Qu5EaLOAd4NyIul3Qm0CMiziokxhYvyZV7\nB2kHcuP4ANTHylVJNwBuTsYEqgLGNE2WZmYNROE5OGn2+3pEHAMQEZ8C70v6FjAkKXYzUAeUPmFG\nREh6MCK2LWTnEfES0L+Qbc2s8ynyhs4mwD8l3Uiuovcs8ENg/YhYCBARCyStV3B8Kco8L2mnQg9g\nZpZWkXfJu5CroP06IvoDH5GrSTa9Ki64/a+lMX26JFXanYDJkmYkAYhc5dM1RzMrqeZ6Iprx/NPM\neP6ZFa7LMweYHRHPJvN3kUuYCyWtHxELJfUE3ik0vpYuySeRy9Z+cMzM2kR1M9e8/frvQr/+uzTO\nP3rzr75QJkmIsyX1i4jXgW8A05LpGOAyYCRQ8Av9LSVMJUHMKHTnZmYrowTPYf4AuEVSDfAWcCxQ\nDdwu6ThgFlDwg8stJcx1JZ3e3Mqmz1KamRWr2Ld4kv56B65g1R7F7TmnpYRZDXSDIu7zm5mthIy/\n6NNiwpwfERe1WSRm1ulVZbx+1mobpplZW2nPNcxvtFkUZmZkf9TIZhNmRCxqy0DMzLLeW1HqccnN\nzMot4/nSCdPMssM1TDOzlDKeL50wzSw7st7jqhOmmWVGc51vZIUTppllRrUTpplZOtlOl06YZpYh\nGa9gOmGaWXa4DdPMLCXfJTczSynrNcysJ3Qz60SUcmpxH1KVpKmS7kvmz5c0R9KUZNqn0PhcwyyT\n9dfoWukQrBWf1Rc8eGBmqQqyf6+5eSWqYY4iN45P97xlV5VilAjXMM0sM6pSTs2R1AfYF/h901Wl\nis/MLBMkpZpacDXwI7449vipkp6X9HtJaxQanxOmmWVGMW2YkvYDFkbE802KXQ9sGhE7AguAgi/N\n3YZpZpnRXOXxpclP8fLkp1rbfDdghKR9gVWBL0v6Y0QcnVfmBmBcwfFFVL7hW1J8vKzycZRSFv5d\nrWUd8J4PXaqga5fy3/SRRESU9ECSYtxLC1KV3X+7ni0eX9IQ4IyIGCGpZ0QsSJafBgyMiCMKidE1\nTDPLDJXnDv/lknYE6oGZwImF7sgJ08wyo1TPrUfE48DjyeejWymemhOmmWVGex6X3MysTWX8zUgn\nTDPLDidMM7OUynTTp2ScMM0sM6qynS+dMM0sO1zDNDNLyW2YZmYpuYZpZpaS2zDNzFJyDdPMLKWs\n1zA7RX+YD49/iB223ZLttu7HlVdcVulwSuKkE45n4z49GdR/h0qHUhId7XwA5s6Zw757f4MBO27L\noP7bc/11v6p0SJlXJaWaKhZfxY7cRurr6zlt1Knc98B4prwwjTtG38Zr06dXOqyiHT3yWMbe/1Cl\nwyiZjnY+AF26dOHSy3/Js8+/zGNPPMUNv72+Q3z3yqkUg6CVU4dPmJMnTaJv382pra2lpqaGgw49\njHHjxlY6rKLtutvX6NGjR6XDKJmOdj4A6/fsyfY77AhAt27d2GLLrZg3b26Fo8q4jGfMNkmYybCX\nUxqGvWxL8+bNpU+fDRvn+/Tuw7y5/tJa25o1cyYvvvg8AwftXOlQMk0p/1RKW930GQW8wvLDXpp1\nCh9++CHfOfxgLr/yv+nWrVulw8m0rD+4XvYaZgvDXraJXr16M3v2243zc+bOoVfv3pUIxTqhTz/9\nlO8cdjCHHfEdho/4VqXDybyMX5G3ySV5c8NetokBAwcyY8abzJo1i6VLl3LnmNEMHz6iEqGUXER0\nqLGDOtr5AJx8wvFsudVW/Of3R1U6lPahiIwpqaukZyRNlfSSpPOT5T0kPSzpNUnjixlmt6yX5PnD\nXkoaSgu/HC6+6ILGz4OHDGXwkKEliaG6upqrr7mO/ffdi/r6ekYem/sCt3fHHHUkTzxRx6J336Xf\nZrWc+9MLOHrksZUOq2Ad7XwAJj71JGNuu4Vttt2OXQf1RxIXXPRz9tx7n0qHttLq6uqoq6sr+3GK\naZ+MiE8kDYuIJZKqgScl/QX4NvBoRFwu6UzgbOCsguIr5290Sb8AvgN8SjLsJXB30zE2PGqkVYJH\njSxcuUaNfPbv76cqO2CTNVobNXI14AngZOBPwJCIWCipJ1AXEVsWEmNZL8kj4pyI2CgiNgUOAx4r\n5YBEZtaxFNuGmTyRMxVYADwSEZOB9SNiIUAy3O56hcbnVyPNLDuayYbPTvw/nnt6QqubR0Q9sJOk\n7sA9krbhi/dPCr62KOsleeogfEluFeBL8sKV65J8ysx/pSrbf+PurR5f0nnAEuC7wNC8S/K/RURB\nNzI6/Js+ZtZ+VCndtCKS1mm4Ay5pVWBP4FXgPuCYpNhIoOBX/XxJbmbZUVyddQPgZklV5CqDYyLi\nQUlPA7dLOg6YBRxS6AGcMM0sM4p8rOgloP8Kli8C9igirEZOmGaWGVl/NdIJ08wyI+P50gnTzDIk\n4xnTCdPMMsNj+piZpeQ2TDOzlDKeL50wzSxDMp4xnTDNLDPchmlmlpLbMM3MUsp4vnTCNLPsUMar\nmE6YZpYZGc+XTphmlh0Zz5dOmGaWIRnPmE6YZpYZfqzIzCylrLdheogKM8uMEowa+QdJCyW9mLfs\nfElzJE0Yyb9iAAAJIklEQVRJpoIHhnfCNLPsKDZjwo3A3itYflVE9E+mhwoNLzOX5NUZr4qvrNKO\np2flUNUBR42sbudVoGLbMCNigqTaFe66BDKTMGuqKx1BqTljmq2sMrZhnirpKOBZ4IyIeL+QnWQm\nYZqZNZcvJ054nIlPPlHobq8HLoqIkHQxcBVwfEHxRVT+ukRSZCEOM0tHEhGlbXiSFLMX/TtV2Q3X\n+lKzx08uycdFxPYrsy6Ndt7iYWYdS/F3fZoWktQzb92BwMuFRudLcjPLjKoi66ySbgWGAmtLehs4\nHxgmaUegHpgJnFjw/rNwKexLcrP2pVyX5PPe+yRV2V5rdi358dNwDdPMMsOvRpqZpZXtfOmEaWbZ\nkfF86YRpZtmR9c43nDDNLDPchmlmlla286UTppllR8bzpROmmWWH2zDNzFJyG6aZWUpZr2G68w0z\ns5RcwzSzzKjKeBXTCdPMMiPj+dIJ08yyI+P50gnTzDIk4xnTCdPMMiPrjxWV/S65pJmSXpA0VdKk\nch+vJXV1dZU8fFn4nLKvo51POUnppua31z6Spkt6XdKZpY6vLR4rqgeGRsROETGoDY7XrI74xfU5\nZV9HO59yKmZEH0lVwHXA3sA2wOGStixlfG2RMNVGxzGz9q64MdAGAW9ExKyIWAaMBr5VyvDaIpEF\n8IikyZK+1wbHM7N2Sin/NKM3MDtvfk6yrHTxlXvwMUkbRMR8SesCjwCnRsSEJmU8AppZO1OGQdBm\nArUpiy+MiPzhc5H0bWDviDghmf8OMCgiflCqGMt+lzwi5id//0PSPeSqzROalMn2rTEzK7uI2LjI\nXcwFNsqb75MsK5myXpJLWk1St+Tz6sBeFDGIuplZCyYDfSXVSloFOAy4r5QHKHcNc33gnuSSuwtw\nS0Q8XOZjmlknFBGfSToVeJhcZfAPEfFqKY9R9jZMM7OOwo/7mJWZlPUuJSytTpEwJVVXOoZSkdRX\n0gBJXSsdS6lI2kbSEElrVzqWUpH0NUlHAUREdISkKWl/SaMqHUcldeh3ySX1i4jXk7aN6oj4rNIx\nFUPScOAXwLvAAknnR8TrFQ6rKJK+CVwGvAXUSDo+IhZUOKyCJW+brAb8Ljer1SPit0nSrIqI+gqH\nWBBJewE/A35U6VgqqcPWMJPk8rykW6GxQbjd1jQl7QpcAYyMiGHAYuCsykZVHElDgWuA70bEAcBS\nYNuKBlWkiKiPiA+Bm4E/ALtKOq1hXUWDK1Dy3fsTcEJEPCJpjeRO9GqVjq2tdciEmTzCdCrwQ2Cp\npD9D+0+awGURMTX5fD6wVju/NF8InBgRkyT1BHYGTpX0O0kHtfPL2E+BDcklzkGSrpJ0iXLa2/+7\nd4FlwAZJs8m9wG+AmzrAz2mltLcfXCoR8RFwHHAr8F/Al/KTZiVjK8IzwN3Q2CbbldxbEd2TZe2u\n/S8iXo2IvyWzxwPXJzXNicBBwDoVC654Y4EFEfFX4FngJKB75LSrmmZEvAbsB1wNvETu/9Vw4CHg\n20CPykXXtjpkwgSIiHkR8WFE/BM4EVi1IWlK6l/qXkzKLSI+i4h/JbMC3gMWJW9QHQlcLGnVykVY\nnIj4eURcnHy+idwvgg0rGlRxPga2SPpPOAm4FNhI0omVDaswEfECuST584i4IWl6+F9yyXKjlrfu\nODr0TZ8GEfFu8kW9QtJ0oBoYVuGwChYRnwIfSpot6RJyb1AdExEfVzi0gkhS5D0QnLwTvD4wr3JR\nFSci5kmaDZwH/GdEjJM0DHizwqEVLCJeAV5pmE9+TusC8ysWVBvrVA+uJ43vZwJ7RsRLlY6nUEmb\nUQ3wavL3NyLijcpGVbykPfY7wOnAoRHRrl+jlbQhsF5EPJfMt9u75PmS79+x5Jq7Do6IaRUOqc10\nmoQpqQdwO3BGRLxY6XhKQdIxwOSO8oWVVAPsCcxI2s06hKY16PYuSZhDyLXRTq90PG2p0yRMAElf\nioh/VzqOUulo/xHNsq5TJUwzs2J02LvkZmal5oRpZpaSE6aZWUpOmGZmKTlhdiCSPpM0RdJLksZI\n+lIR+xoiaVzyeX9JP26h7BqSTi7gGOdLOj3t8iZlbpR04Eocq1ZSu3321rLBCbNj+Sgi+kfEduQ6\nSzipaYGV7CghACJiXERc3kK5HsApKxVpZfiRECuKE2bH9X98PiDUdEk3JzWsPpL2lPSUpGeTmuhq\nAJL2kfSqpGeBxtqbpJGSrk0+ryfpbknPS5oqaRfgEmCzpHZ7WVLuvyRNSsqdn7evn0h6TdITwBat\nnYSk7yb7mSrpjia15j2VG+9+uqT9kvJVki6X9Exy7O8V/S9plnDC7FgEIKkL8E1yPcsAbA5cl9Q8\nlwDnknudcgDwHHB68lri/wD7Jct7Ntl3Q+3sV0BdROwI9AemkeuX882kdnumpD2BzSNiELATMEC5\nHsj7A4cA25Pr/WZginO6KyIGRcROwHRyvRo1qI2IgeQ6hfitciMFHg+8FxE7kxvS+QRJace6NmtR\np+h8oxNZVdKU5PP/kevAtjcwMyImJ8t3AbYGnsx7J30isCXwVkS8lZT7M7Ci2tnuQOPQC8AHktZq\nUmYvcrW/KeSS+OrkknZ34J6I+AT4RFKaIVC3l/QzYM1kP+Pz1t2exPGmpBnJOewFbCfp4KRM9+TY\n7f5de6s8J8yOZUlE9M9fkDRZfpS/CHg4Io5sUm6HZF1r0rQDCrgkIm5ocoxCxoO5ERgRES9LGknu\nHeYVxaJkXsD3I+KRJsd2LdOK5kvyjqW5hJe//GlgN0mbAUhaTdLm5C53ayVtkpQ7vJl9/ZXkBk/S\nXtgd+AD4cl6Z8cBxyvV8j6RektYFngAOkNRV0peB/VOcUzdy4xfVAEc2WXewcjYDNgFeS459StIs\ngaTN9Xk/oZ2mZ3ArD9cwO5bman+NyyPin0kvR7cl7ZYBnBsRbyjXZ+iDkj4id0nfbQX7+iHwP5KO\nJzcMw8kR8UxyE+lF4C9JO+ZWwMSkhvsB8J2ImCrpduBFcsNTTEpxTj9Nyr1Drtf5/MT8drLuy+SG\nulgq6ffAxsCUpMnhHeCAVv59zFJx5xtmZin5ktzMLCUnTDOzlJwwzcxScsI0M0vJCdPMLCUnTDOz\nlJwwzcxScsI0M0vp/wGGC2A9cwP0NAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25d239798d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnf_matrix = confusion_matrix(conf.KIScore, predicted_ch)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Graded answers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uncern.to_csv('Manual_Grading.csv' , index = False)\n",
    "conf.to_csv('Graded.csv' , index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding Code for summarising responses\n",
    "\n",
    "Starting with lesk if I need it - Turned out to be quite useless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "\n",
    "sent = \"I picked these choices because, dark colors like black are known to absorb heat. Light colors like white are known to reflect light. This explains my choices.\"\n",
    "\n",
    "#tagged = nltk.pos_tag(word_tokenize(sent)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
