{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatically Scoring Student Responses\n",
    "\n",
    "Avi Dixit and Elizabeth McBride\n",
    "\n",
    "<b>Introduction </b> Notebook to upload the pre and post test data into pandas dataframes and apply classification algorithms to it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#imports - Consolidated imports for all functions used (or will eventually be used) by the notebook\n",
    "\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "%matplotlib inline\n",
    "\n",
    "import re\n",
    "import math\n",
    "import string\n",
    "from collections import Counter\n",
    "from __future__ import division\n",
    "from time import time\n",
    "import logging\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty plot confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "class_names = [1, 2, 3, 4, 5]\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#read_file is a helper function to get the '|' delimited CSV into a data frame\n",
    "def read_file(filename):\n",
    "    #get the file\n",
    "    df = pd.read_csv(filename, error_bad_lines=False, encoding = 'mbcs')\n",
    "    \n",
    "    #Force KIScore to int, otherwise reverts to float. Same for Answer. Forcing NaN to unicode\n",
    "    df['KIScore'] = df['KIScore'].astype(int)\n",
    "    df['Answer'] = df['Answer'].astype(str)\n",
    "    # Filters if needed later on\n",
    "    #filtered_data = df[\"Answer\"].notnull()\n",
    "    #filtered_data = df[df[\"KIScore\"] != 1 & df['Answer'].notnull() & df[\"KIScore\"].notnull()]\n",
    "    #df_narrative = df[filtered_data]\n",
    "    return df\n",
    "\n",
    "#reads in the training data into a panda - Steve \n",
    "#(code based on ANLP Notebook Intro to Pandas by Marti Hearst and Andrea Gagliano)\n",
    "def read_training_data(filename):\n",
    "    df_narrative = read_file(filename)\n",
    "    #print the report on category breakdown, might need these counts later\n",
    "    #print(\"Creating training data... category breakdown:\")\n",
    "    #sorted_product_counts = df_narrative.Category.value_counts(ascending=True)\n",
    "    #print(sorted_product_counts)\n",
    "    #sorted_product_counts.plot(kind='barh', figsize=(8,6), title=\"Categories\");\n",
    "    return df_narrative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperate the data into training and dev data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#breaks the panda into a training set and a dev set - Currently only genereates dev and test data\n",
    "#Modify the function later to keep some data as test data as well\n",
    "\n",
    "def get_train_and_dev_sets(full_data, percent_dev):\n",
    "    #randomize the indices\n",
    "    random_index = np.random.permutation(full_data.index)\n",
    "    full_data_shuffled = full_data.ix[random_index, ['WISEID', 'Answer', 'KIScore']]\n",
    "    full_data_shuffled.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    #break down the counts for the shuffled data\n",
    "    rows, columns = full_data_shuffled.shape\n",
    "    train_size = round(rows*(1 - percent_dev))\n",
    "    dev_size   = round(rows*percent_dev)\n",
    "    \n",
    "    #separate the training data from the development data\n",
    "    train_data = full_data_shuffled.loc[:train_size]\n",
    "    dev_data = full_data_shuffled.loc[train_size:dev_size+train_size].reset_index(drop=True)\n",
    "\n",
    "    return train_data, dev_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reads in the test file into a panda\n",
    "def read_test_data(filename):\n",
    "    #get the file\n",
    "    df = read_file(filename)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#the code that calls the above functions - puts the data into a data frame\n",
    "df = read_training_data(\"Laura_Question/Laura1.csv\")\n",
    "train_set, dev_set = get_train_and_dev_sets(df,.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spell checker created by Peter Norvig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TEXT = open('big.txt').read()\n",
    "\n",
    "def tokens(text):\n",
    "    \"List all the word tokens (consecutive letters) in a text. Normalize to lowercase.\"\n",
    "    #print(re.findall('[a-z]+', text.lower()))\n",
    "    return re.findall('[a-z]+', text.lower())\n",
    "\n",
    "def tokens_target(text):\n",
    "    \"List all the word tokens (consecutive letters) in a text. Normalize to lowercase.\"\n",
    "    words = re.findall('[a-z]+', text.lower())\n",
    "    tagged_POS_sents = nltk.pos_tag(words) # tags sents\n",
    "    #normed_tagged_words = [wnl.lemmatize(word[0].lower()) for sent in tagged_POS_sents\n",
    "                           #for word in sent \n",
    "                           #if word[0].lower() not in nltk.corpus.stopwords.words('english')\n",
    "                           #and word[0] not in punctuation # remove punctuation\n",
    "                           #and not re.search(r'''^[\\.,;\"'?!():\\-_`]+$''', word[0])\n",
    "                           #and word[1].startswith('N')]  # include only nouns\n",
    "    #print(tagged_POS_sents)\n",
    "    if (len(tagged_POS_sents) > 1):\n",
    "        normed_tagged_words = [word[0].lower() for word in tagged_POS_sents\n",
    "                              if (word[1].startswith('N') or word[1].startswith('J') or word[1].startswith('V'))]\n",
    "        return normed_tagged_words\n",
    "    else:\n",
    "        return words\n",
    "\n",
    "WORDS = tokens(TEXT)\n",
    "\n",
    "COUNTS = Counter(WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def correct(word):\n",
    "    \"Find the best spelling correction for this word.\"\n",
    "    # Prefer edit distance 0, then 1, then 2; otherwise default to word itself.\n",
    "    candidates = (known(edits0(word)) or \n",
    "                  known(edits1(word)) or \n",
    "                  known(edits2(word)) or \n",
    "                  [word])\n",
    "    return max(candidates, key=COUNTS.get)\n",
    "\n",
    "# Show what happens in the case of ties\n",
    "def correct_under_hood (word):\n",
    "    candidates = (known(edits0(word)) or \n",
    "                  known(edits1(word)) or \n",
    "                  known(edits2(word)) or \n",
    "                  [word])\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def known(words):\n",
    "    \"Return the subset of words that are actually in the dictionary.\"\n",
    "    return {w for w in words if w in COUNTS}\n",
    "\n",
    "def edits0(word): \n",
    "    \"Return all strings that are zero edits away from word (i.e., just word itself).\"\n",
    "    return {word}\n",
    "\n",
    "def edits2(word):\n",
    "    \"Return all strings that are two edits away from this word.\"\n",
    "    return {e2 for e1 in edits1(word) for e2 in edits1(e1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def edits1(word):\n",
    "    \"Return all strings that are one edit away from this word.\"\n",
    "    pairs      = splits(word)\n",
    "    deletes    = [a+b[1:]           for (a, b) in pairs if b]\n",
    "    transposes = [a+b[1]+b[0]+b[2:] for (a, b) in pairs if len(b) > 1]\n",
    "    replaces   = [a+c+b[1:]         for (a, b) in pairs for c in alphabet if b]\n",
    "    inserts    = [a+c+b             for (a, b) in pairs for c in alphabet]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def splits(word):\n",
    "    \"Return a list of all possible (first, rest) pairs that comprise word.\"\n",
    "    return [(word[:i], word[i:]) \n",
    "            for i in range(len(word)+1)]\n",
    "\n",
    "alphabet = 'abcdefghijklmnopqrstuvwxyz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spell_checker = lambda x : ' '.join(i for i in list(map(correct, tokens(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_set['Answer'] = train_set['Answer'].apply(spell_checker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WISEID</th>\n",
       "      <th>Answer</th>\n",
       "      <th>KIScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>118526.0</td>\n",
       "      <td>I picked these answers because the sun likes d...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>118482.0</td>\n",
       "      <td>because</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>118413.0</td>\n",
       "      <td>the light colered fabric will help because it ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>149588.0</td>\n",
       "      <td>I picked the third one because if you put a li...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>150063.0</td>\n",
       "      <td>Light colors reflect light so not as much heat...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     WISEID                                             Answer  KIScore\n",
       "0  118526.0  I picked these answers because the sun likes d...        2\n",
       "1  118482.0                                           because         2\n",
       "2  118413.0  the light colered fabric will help because it ...        5\n",
       "3  149588.0  I picked the third one because if you put a li...        3\n",
       "4  150063.0  Light colors reflect light so not as much heat...        4"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dev_set['Answer'] = dev_set['Answer'].apply(spell_checker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WISEID</th>\n",
       "      <th>Answer</th>\n",
       "      <th>KIScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>136380.0</td>\n",
       "      <td>Darker colors absorb the light so it will make...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>151188.0</td>\n",
       "      <td>I think this because when i wear a black shirt...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150162.0</td>\n",
       "      <td>Well, I get my choice by thinking in my head (...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>136361.0</td>\n",
       "      <td>Black adsorbs and white reflects. So light clo...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151198.0</td>\n",
       "      <td>light colors reflect the sun and dark colors a...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     WISEID                                             Answer  KIScore\n",
       "0  136380.0  Darker colors absorb the light so it will make...        5\n",
       "1  151188.0  I think this because when i wear a black shirt...        3\n",
       "2  150162.0  Well, I get my choice by thinking in my head (...        2\n",
       "3  136361.0  Black adsorbs and white reflects. So light clo...        4\n",
       "4  151198.0  light colors reflect the sun and dark colors a...        3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Strategies that need to be attempted </b>\n",
    "1. Feature Selection attempted:\n",
    "    1. counts of Unigrams only \n",
    "    2. ... Unigrams and Bigrams\n",
    "    3. ... Unigrams, Bigrams, and Trigrams\n",
    "    4. ... Bigrams and Trigrams\n",
    "    5. ... 4- and 5-gram combinations\n",
    "    6. The use of TF-IDF, with IDF and without\n",
    "    7. Word tokens that included punctuation and numbers\n",
    "    8. Word tokens with letters only, filtering punctuation or splitting on punctuation\n",
    "    9. Lemmatizing using Word Net\n",
    "    10. Stemming using Snowball\n",
    "    11. With and without stopwords\n",
    "    12. With and without lowercasing\n",
    "    13. Chunking out all words that are not nouns.\n",
    "    14. Stemming user Porter and Lancaster stemmers.\n",
    "    15. Checking most common hypernyms of nouns in the review to categorise reviews better.\n",
    "    16. Using feature unions in pipelines to select specific features.\n",
    "2. Classifiers used:\n",
    "    1. Linear: Naive Bayes, Linear Regression, Stochastic Gradiant Descent\n",
    "    2. SVC and Linear SVC (One vs One, One vs Many)\n",
    "    3. K - Nearest Neighbor\n",
    "    4. MLP\n",
    "    5. Voting classifiers with hard and soft voting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def transform_dfs_to_arrays(train_set, dev_set):\n",
    "    vec = CountVectorizer(ngram_range=(1, 4), token_pattern=r'\\b\\w+\\b', stop_words=\"english\", max_features=5000)\n",
    "    arr_train_feature_sparse = vec.fit_transform(train_set[\"Answer\"].values.astype(str))\n",
    "    arr_train_feature = arr_train_feature_sparse.toarray()\n",
    "    \n",
    "    arr_dev_feature_sparse = vec.transform(dev_set[\"Answer\"].values.astype(str))\n",
    "    arr_dev_feature = arr_dev_feature_sparse.toarray()\n",
    "        \n",
    "    return arr_train_feature, arr_dev_feature\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets start with a simple Naive Bayes classifier for Multinomial models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_NB_model(train_set, arr_train):\n",
    "    nb = MultinomialNB()\n",
    "    nb_model = nb.fit(arr_train, \n",
    "                      train_set.KIScore)\n",
    "    return nb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arr_train, arr_dev = transform_dfs_to_arrays(train_set, dev_set)\n",
    "nb_model = train_NB_model(train_set, arr_train)\n",
    "nb_predictions = nb_model.predict(arr_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68632707774798929"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(dev_set.KIScore, nb_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try K-nearest neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_KNearest_model(train_set, arr_train):\n",
    "    #Should add and experiement with more parameters and algorithms for nearest neighbor\n",
    "    nb = KNeighborsClassifier(n_neighbors=5)\n",
    "    nb_model = nb.fit(arr_train, \n",
    "                      train_set.KIScore)\n",
    "    return nb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53619302949061665"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh_model = train_KNearest_model(train_set, arr_train)\n",
    "ne_predictions = neigh_model.predict(arr_dev)\n",
    "accuracy_score(dev_set.KIScore, ne_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Not bad for a start, lets move onto Logistical Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_LR_model(train_set, arr_train):\n",
    "    logreg = LogisticRegression()\n",
    "    lr_model = logreg.fit(arr_train, train_set.KIScore)\n",
    "    return lr_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr_model = train_LR_model(train_set, arr_train)\n",
    "lr_predictions = lr_model.predict(arr_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69168900804289546"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(dev_set.KIScore, lr_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Already nearing 80s!!!! But remember, need to measure Cohen's Kappa, not percetage correct. Also start plotting confusion matrix and extract errors once the classifiers are worked out.\n",
    "\n",
    "Lets start with the pipeline for the best features and get to feature detections using SVM. Also need to perform all the combinations mentioned before (Including preprocessing). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "        #self.snow = SnowballStemmer('english')\n",
    "    \n",
    "    #this code will filter punctuation from a word and rejoin it together (\"they're\" becomes \"theyre\")\n",
    "    def __preprocess(self, doc):\n",
    "       filter_punc = lambda t: ''.join([x.lower() for x in t if x.isalpha()])\n",
    "       words = [x for x in map(filter_punc, doc.split()) if x]\n",
    "       review = \"\"\n",
    "       for w in words:\n",
    "           review = review+\" \"+w\n",
    "       return review\n",
    "    \n",
    "    #Multiple attempts to select lemmas and stems from a word token (using NLTK)\n",
    "    def __call__(self, doc):\n",
    "        #return [self.wnl.lemmatize(t.lower()) for t in word_tokenize(doc)]\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(self.__preprocess(doc))]\n",
    "        #return [\"\".join([str(s.name()) for s in wn.synset(t).hypernyms()]) for t in word_tokenize(self.__preprocess(doc))]\n",
    "        #return [self.snow.stem(t) for t in word_tokenize(self.__preprocess(doc))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from nltk import FreqDist\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "from string import punctuation\n",
    "    \n",
    "def stuff(doc):\n",
    "    #flatten = [w for sent in doc for w in sent]\n",
    "    flatten = [w for w in word_tokenize(doc)]\n",
    "    unigram_counts = Counter(flatten)\n",
    "    uni_dist = FreqDist(unigram_counts)\n",
    "    uni = [a for (a, b) in uni_dist.most_common(25)]\n",
    "    \n",
    "    sent_tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "    raw_sents = sent_tokenizer.tokenize(doc) # Split text into sentences\n",
    "    words = [nltk.word_tokenize(word) for word in raw_sents]\n",
    "    wnl = WordNetLemmatizer() # to get word stems\n",
    "    tagged_POS_sents = [nltk.pos_tag(word) for word in words ] # tags sents\n",
    "    #print(tagged_POS_sents)\n",
    "    #normed_tagged_words = [wnl.lemmatize(word[0].lower()) for sent in tagged_POS_sents\n",
    "                           #for word in sent \n",
    "                           #if word[0].lower() not in nltk.corpus.stopwords.words('english')\n",
    "                           #and word[0] not in punctuation # remove punctuation\n",
    "                           #and not re.search(r'''^[\\.,;\"'?!():\\-_`]+$''', word[0])\n",
    "                           #and word[1].startswith('N')]  # include only nouns\n",
    "    normed_tagged_words = [word[0].lower() for sent in tagged_POS_sents\n",
    "                          for word in sent\n",
    "                          if (word[1].startswith('N') or word[1].startswith('J'))]\n",
    "    #normed_tagged_words = list(set(normed_tagged_words))\n",
    "    return normed_tagged_words\n",
    "\n",
    "#from http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n",
    "class LemmaTokenizer1(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = PorterStemmer()\n",
    "    def __call__(self, doc):\n",
    "        return [t for t in stuff(doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pipeline attempts - Best features will be decided using Grid Search. Lets just setup a baseline for now.\n",
    "#from http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n",
    "#Note: add probability True to SVC classifier to be able to use predict probability function, which\n",
    "# is crucial for the the ensemble methods tried later\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer(ngram_range=(1, 2), tokenizer=LemmaTokenizer(),  \n",
    "                                              max_df=0.25, max_features= 15000, token_pattern=r'\\b\\w+\\b', \n",
    "                                              stop_words=\"english\")),\n",
    "                      ('tfidf', TfidfTransformer(use_idf = True, norm='l2')),\n",
    "                      ('log', LogisticRegression(class_weight = None )),\n",
    "                      ('clf', SVC(C = 1000000.0, gamma='auto', kernel='linear', probability = True))])\n",
    "                      #('clf', LinearSVC(C=1.0, random_state=69, penalty='l2', dual=True, tol=1e-5, class_weight = None))])\n",
    "                      #('clf', OneVsOneClassifier(LinearSVC(random_state=0)))])                    \n",
    "                      #('clf', SGDClassifier(loss='hinge', alpha=1e-5, penalty='elasticnet', n_iter=50, random_state=69))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.63538873994638068"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_predictor = text_clf.fit(train_set[\"Answer\"], \n",
    "                                  train_set.KIScore)\n",
    "\n",
    "predicted = pipeline_predictor.predict(dev_set[\"Answer\"])\n",
    "accuracy_score(dev_set.KIScore, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>134</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>55</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>25</td>\n",
       "      <td>168</td>\n",
       "      <td>116</td>\n",
       "      <td>44</td>\n",
       "      <td>20</td>\n",
       "      <td>373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   1    2    3   4   5  All\n",
       "True                                \n",
       "1          13    0    0   0   0   13\n",
       "2          10  134   31   3   2  180\n",
       "3           2   30   55   8   2   97\n",
       "4           0    4   27  26   7   64\n",
       "5           0    0    3   7   9   19\n",
       "All        25  168  116  44  20  373"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(dev_set.KIScore, predicted, \n",
    "           rownames=['True'], colnames=['Predicted'], \n",
    "            margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try some ensemble classifiers (Both averaging and boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7024128686327078"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "forest_clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "f_clf = Pipeline([\n",
    "  ('feature_selection', SelectFromModel(LinearSVC(C = 100, penalty=\"l1\", dual = False))),\n",
    "  ('classification', forest_clf)\n",
    "])\n",
    "\n",
    "forest_predictor = f_clf.fit(arr_train, train_set.KIScore)\n",
    "f_predicted = forest_predictor.predict(arr_dev)\n",
    "accuracy_score(dev_set.KIScore, f_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5630026809651475"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_clf = AdaBoostClassifier(n_estimators=100)\n",
    "\n",
    "ada_predictor = ada_clf.fit(arr_train, train_set.KIScore)\n",
    "a_predicted = ada_predictor.predict(arr_dev)\n",
    "accuracy_score(dev_set.KIScore, a_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69168900804289546"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_hastie_10_2\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "grad_clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n",
    "                                      max_depth=1, random_state=0).fit(arr_train, train_set.KIScore)\n",
    "grad_predictor = grad_clf.fit(arr_train, train_set.KIScore)\n",
    "grad_predicted = grad_predictor.predict(arr_dev)\n",
    "accuracy_score(dev_set.KIScore, grad_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And moving on to voting classifier with hard voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 1.07, NNZs: 5000, Bias: 1.389857, T: 1494, Avg. loss: 0.516395\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.22, NNZs: 5000, Bias: 1.657483, T: 2988, Avg. loss: 0.382663\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.31, NNZs: 5000, Bias: 1.773445, T: 4482, Avg. loss: 0.321512\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.41, NNZs: 5000, Bias: 1.856578, T: 5976, Avg. loss: 0.285137\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.49, NNZs: 5000, Bias: 1.893826, T: 7470, Avg. loss: 0.260392\n",
      "Total training time: 0.11 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6836461126005362"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = RandomForestClassifier(random_state=1, n_estimators = 100)\n",
    "clf3 = GaussianNB()\n",
    "clf4 = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n",
    "                                      max_depth=1, random_state=0)\n",
    "clf5 = SGDClassifier(loss='hinge', alpha=1e-5, penalty='elasticnet', n_iter=50, random_state=69)\n",
    "clf6 = SVC(C = 1000000.0, gamma='auto', kernel='rbf', probability = True)\n",
    "clf8 = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(5, 2), random_state=1)\n",
    "clf9 = SGDRegressor(shuffle = True, verbose = 1)\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3), \n",
    "                                    ('clf6', clf6),\n",
    "                                   ('clf4', clf4), ('clf5', clf5), ('clf8', clf8),\n",
    "                                   ('clf9', clf9)], voting='hard')\n",
    "\n",
    "eclf_predictor = eclf.fit(arr_train, train_set.KIScore)\n",
    "v_predicted = eclf_predictor.predict(arr_dev)\n",
    "accuracy_score(dev_set.KIScore, v_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for clf, label in zip([clf1, clf2, clf3, clf4, clf5, clf6, clf8, eclf], ['Logistic Regression', 'Random Forest', \n",
    "                                                                  'naive Bayes', 'Gradient Boosting', 'SGD', 'SVC', \n",
    "                                                                  'MLP', 'Ensemble']):\n",
    "    scores = cross_val_score(clf, arr_train, train_set.KIScore, cv=5, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Voting classifier with soft voting\n",
    "\n",
    "Note: The MLP classifier improved accuracy for both hard and sofr voting\n",
    "\n",
    "But, I need to do a ton of cross validation for the correct parameters and classifiers for each question type. Not to mention, need to get the grid search working well for these things.\n",
    "\n",
    "TODO: Find optimal weights for the classifiers\n",
    "\n",
    "TODO: Need to do feature engineering to get better parameters. This isnt working too well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = RandomForestClassifier(random_state=1, n_estimators = 100)\n",
    "clf3 = GaussianNB()\n",
    "clf4 = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n",
    "                                      max_depth=1, random_state=0)\n",
    "clf6 = SVC(C = 1000000.0, gamma='auto', kernel='rbf', probability = True)\n",
    "clf8 = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(5, 2), random_state=1)\n",
    "\n",
    "eclf_s = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3), \n",
    "                                    ('clf6', clf6),\n",
    "                                   ('clf4', clf4), ('clf8', clf8)], voting='soft')\n",
    "\n",
    "eclf_s_predictor = eclf_s.fit(arr_train, train_set.KIScore)\n",
    "s_predicted = eclf_s_predictor.predict(arr_dev)\n",
    "accuracy_score(dev_set.KIScore, s_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for clf, label in zip([clf1, clf2, clf3, clf4, clf6, clf8, eclf], ['Logistic Regression', 'Random Forest', \n",
    "                                                                  'naive Bayes', 'Gradient Boosting', 'SVC', \n",
    "                                                                  'MLP', 'Ensemble']):\n",
    "    scores = cross_val_score(clf, arr_train, train_set.KIScore, cv=5, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets use a brute force method to find the optimal weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "df = pd.DataFrame(columns=('w1', 'w2', 'w4', 'w5', 'w6', 'mean', 'std'))\n",
    "\n",
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = RandomForestClassifier(random_state=1, n_estimators = 100)\n",
    "clf3 = GaussianNB()\n",
    "clf4 = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n",
    "                                      max_depth=1, random_state=0)\n",
    "clf6 = SVC(C = 1000000.0, gamma='auto', kernel='rbf', probability = True)\n",
    "clf8 = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(5, 2), random_state=1)\n",
    "\n",
    "t0 = time()\n",
    "i = 0\n",
    "for w1 in range(1,4):\n",
    "    for w2 in range(1,4):\n",
    "        for w4 in range(1,4):\n",
    "            for w5 in range(1,4):\n",
    "                for w6 in range(1,4):\n",
    "                        if len(set((w1,w2,w4,w5,w6))) == 1: # skip if all weights are equal\n",
    "                            continue\n",
    "                        t0 = time()\n",
    "                        eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), \n",
    "                                    ('clf6', clf6),\n",
    "                                   ('clf4', clf4), ('clf8', clf8)], \n",
    "                                                  weights=[w1, w2, w4, w5, w6], voting = 'soft')\n",
    "                        scores = cross_val_score(eclf, \n",
    "                                                 arr_train,\n",
    "                                                 train_set.KIScore,\n",
    "                                                 cv=3,\n",
    "                                                 scoring='accuracy',\n",
    "                                                 n_jobs= -1)\n",
    "                        \n",
    "                        print(\"done in %0.3fs\" % (time() - t0))\n",
    "                        df.loc[i] = [w1, w2, w4, w5, w6, scores.mean(), scores.std()]\n",
    "                        i += 1\n",
    "                        \n",
    "#print(\"done in %0.3fs\" % (time() - t0))\n",
    "df.sort(columns=['mean', 'std'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cohen_kappa_score(dev_set.KIScore, lr_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71045576407506705"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = RandomForestClassifier(random_state=1, n_estimators = 100)\n",
    "clf3 = GaussianNB()\n",
    "clf4 = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n",
    "                                      max_depth=1, random_state=0)\n",
    "clf6 = SVC(C = 1000000.0, gamma='auto', kernel='rbf', probability = True)\n",
    "clf8 = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(5, 2), random_state=1)\n",
    "\n",
    "eclf_w = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), \n",
    "                                    ('clf6', clf6),\n",
    "                                   ('clf4', clf4), ('clf8', clf8)], \n",
    "                                                  weights=[3, 3, 1, 2, 1], voting = 'soft')\n",
    "\n",
    "eclf_w_predictor = eclf_w.fit(arr_train, train_set.KIScore)\n",
    "w_predicted = eclf_w_predictor.predict(arr_dev)\n",
    "accuracy_score(dev_set.KIScore, w_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woops! Not very good\n",
    "\n",
    "Lets see which categories we are getting wrong (Don't be 2!!!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.crosstab(dev_set.KIScore, w_predicted, \n",
    "           rownames=['True'], colnames=['Predicted'], \n",
    "            margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hm, it looks like we should try and get more data. Might not be possible without mixing up student responses.\n",
    "\n",
    "To squeeze voting classifiers into the grid, I'm restricted to using only classifiers that provide a predict_pobability function. Might be worth trying later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SVC())\n",
    "])\n",
    "\n",
    "\n",
    "# uncommenting more parameters will give better exploring power but will\n",
    "# increase processing time in a combinatorial way\n",
    "parameters = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    'vect__max_features': (None, 5000, 10000, 20000),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'tfidf__norm': ('l1', 'l2'),\n",
    "    #'clf__alpha': (0.00001, 0.000001),\n",
    "    #'clf__penalty': ('l1', 'l2'),\n",
    "    #'clf_kernel': ('rbf', 'linear'),\n",
    "    'clf__C': (1000, 10000)\n",
    "    #'clf__n_iter': (10, 50, 80),\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV( pipeline, parameters, n_jobs=-1, verbose=1, cv = 9)\n",
    "\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters:\")\n",
    "pprint(parameters)\n",
    "t0 = time()\n",
    "grid_search.fit(train_set[\"Answer\"], train_set.KIScore)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted_grid = grid_search.predict(dev_set[\"Answer\"])\n",
    "accuracy_score(dev_set.KIScore, predicted_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cohen_kappa_score(dev_set.KIScore, predicted_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now that we have exhausted all classifiers without really messing around with feature engineering or feature selection, lets add custom features to the pipeline using FeatureUnion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Final Classifier for Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71581769436997322"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Starting with a feature on the length of the answer\n",
    "#Every class created for the custom feature needs to have a method to transform and fit the data\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.decomposition import PCA\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "ps = PorterStemmer()\n",
    "\n",
    "#Filter for question 3 to remove the David's claim condition at start\n",
    "filter_answer = lambda x : ' '.join(i for i in x.split() if not (i.startswith('david') or\n",
    "                                                                  i.startswith('claim')))\n",
    "\n",
    "#train_set['Answer'] = train_set['Answer'].apply(filter_answer)\n",
    "#dev_set['Answer'] = dev_set['Answer'].apply(filter_answer)\n",
    "\n",
    "class TextStats(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Extract features from each document for DictVectorizer\"\"\"\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, posts):\n",
    "        return [{'length': len(text)}\n",
    "                for text in posts.tolist()]\n",
    "\n",
    "class Keywords_Radiation(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Extract features from each document for DictVectorizer\"\"\"\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, posts):\n",
    "        return [{'Radiation': 'radiat' in [ps.stem(i) for i in text.split()]\n",
    "                or 'energi' in [ps.stem(i) for i in text.split()]}\n",
    "                for text in posts.tolist()]\n",
    "    \n",
    "class Trap_Radiation(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Extract features from each document for DictVectorizer\"\"\"\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, posts):\n",
    "        return [{'Radiation': 'trap' in [ps.stem(i) for i in text.split()]\n",
    "                               or 'keep' in [ps.stem(i) for i in text.split()]}\n",
    "                for text in posts.tolist()]\n",
    "    \n",
    "#Required to convert a sparse matrix to a dense matrix. Vectorizers give out a sparse matrix but some \n",
    "#classifiers need a dense matrix to perform classification\n",
    "class DenseTransformer(TransformerMixin):\n",
    "\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X.todense()\n",
    "\n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        self.fit(X, y, **fit_params)\n",
    "        return self.transform(X)\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    \n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('features', FeatureUnion(\n",
    "        transformer_list=[\n",
    "        ('body_stats', Pipeline([\n",
    "                    ('stats', TextStats()),  # returns a list of dicts\n",
    "                    ('vect', DictVectorizer())  # list of dicts -> feature matrix\n",
    "        ])),\n",
    "        ('key_words_radiate', Pipeline([ # Give low weight\n",
    "                    ('Radiation', Keywords_Radiation()),  # returns a list of dicts\n",
    "                    ('vect', DictVectorizer())  # list of dicts -> feature matrix\n",
    "        ])),\n",
    "        ('key_words_trap', Pipeline([ # Give low weight\n",
    "                    ('Radiation', Trap_Radiation()),  # returns a list of dicts\n",
    "                    ('vect', DictVectorizer())  # list of dicts -> feature matrix\n",
    "        ])),\n",
    "        ('bag_of', Pipeline([\n",
    "                    ('vect', CountVectorizer(ngram_range=(1, 3), tokenizer=LemmaTokenizer(),  \n",
    "                                              max_df=0.25, max_features= 15000, token_pattern=r'\\b\\w+\\b', \n",
    "                                              stop_words=\"english\"))\n",
    "                    #('tfidf_transformer', TfidfTransformer(use_idf = True, norm='l2'))\n",
    "        ]))\n",
    "    ],\n",
    "    # weight components in FeatureUnion\n",
    "        transformer_weights={\n",
    "            'body_stats': 1,\n",
    "            'key_words_radiate': 1.0,\n",
    "            'key_words_trap': 1.0,\n",
    "            'bag_of': 1.0        \n",
    "        },\n",
    "    )),\n",
    "    ('to_dense', DenseTransformer()),   \n",
    "    ('feature_selection', SelectFromModel(ExtraTreesClassifier(), prefit=False)),\n",
    "    #('dim', LinearDiscriminantAnalysis(n_components=2)),\n",
    "    #('clf', SVC(kernel='linear'))  # classifier\n",
    "    ('clf', eclf_w)  # classifier\n",
    "])\n",
    "\n",
    "\n",
    "p_predictor = pipeline.fit(train_set['Answer'], \n",
    "                                  train_set.KIScore)\n",
    "\n",
    "predicted = p_predictor.predict(dev_set['Answer'].values)\n",
    "accuracy_score(dev_set.KIScore, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier for Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72386058981233248"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Starting with a feature on the length of the answer\n",
    "#Every class created for the custom feature needs to have a method to transform and fit the data\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.decomposition import PCA\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "ps = PorterStemmer()\n",
    "\n",
    "#Filter for question 3 to remove the David's claim condition at start\n",
    "filter_answer = lambda x : ' '.join(i for i in x.split() if not (i.startswith('david') or\n",
    "                                                                  i.startswith('claim')))\n",
    "\n",
    "#train_set['Answer'] = train_set['Answer'].apply(filter_answer)\n",
    "#dev_set['Answer'] = dev_set['Answer'].apply(filter_answer)\n",
    "\n",
    "class TextStats(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Extract features from each document for DictVectorizer\"\"\"\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, posts):\n",
    "        return [{'length': len(text)}\n",
    "                for text in posts.tolist()]\n",
    "\n",
    "class Keywords_Radiation(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Extract features from each document for DictVectorizer\"\"\"\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, posts):\n",
    "        return [{'Radiation': 'radiat' in [ps.stem(i) for i in text.split()]\n",
    "                or 'energi' in [ps.stem(i) for i in text.split()]}\n",
    "                for text in posts.tolist()]\n",
    "    \n",
    "class Keywords_Dark(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Extract features from each document for DictVectorizer\"\"\"\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, posts):\n",
    "        return [{'Dark': ('dark' in [ps.stem(i) for i in text.split()]\n",
    "                          or 'black' in [ps.stem(i) for i in text.split()])\n",
    "                and 'absorb' in [ps.stem(i) for i in text.split()]}\n",
    "                for text in posts.tolist()]\n",
    "    \n",
    "class Keywords_Light(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Extract features from each document for DictVectorizer\"\"\"\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, posts):\n",
    "        return [{'Dark': ('light' in [ps.stem(i) for i in text.split()]\n",
    "                          or 'white' in [ps.stem(i) for i in text.split()])\n",
    "                and 'reflect' in [ps.stem(i) for i in text.split()]}\n",
    "                for text in posts.tolist()]    \n",
    "    \n",
    "class Keywords_Albedo(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Extract features from each document for DictVectorizer\"\"\"\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, posts):\n",
    "        return [{'Albedo': 'albedo' in [ps.stem(i) for i in text.split()]}\n",
    "                for text in posts.tolist()]\n",
    "    \n",
    "class Trap_Radiation(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Extract features from each document for DictVectorizer\"\"\"\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, posts):\n",
    "        return [{'Trap': 'trap' in [ps.stem(i) for i in text.split()]\n",
    "                               or 'keep' in [ps.stem(i) for i in text.split()]}\n",
    "                for text in posts.tolist()]\n",
    "    \n",
    "#Required to convert a sparse matrix to a dense matrix. Vectorizers give out a sparse matrix but some \n",
    "#classifiers need a dense matrix to perform classification\n",
    "class DenseTransformer(TransformerMixin):\n",
    "\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X.todense()\n",
    "\n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        self.fit(X, y, **fit_params)\n",
    "        return self.transform(X)\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    \n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('features', FeatureUnion(\n",
    "        transformer_list=[\n",
    "        ('body_stats', Pipeline([\n",
    "                    ('stats', TextStats()),  # returns a list of dicts\n",
    "                    ('vect', DictVectorizer())  # list of dicts -> feature matrix\n",
    "        ])),\n",
    "        ('key_words_dark', Pipeline([ # Give low weight\n",
    "                    ('Radiation', Keywords_Dark()),  # returns a list of dicts\n",
    "                    ('vect', DictVectorizer())  # list of dicts -> feature matrix\n",
    "        ])),\n",
    "        ('key_words_light', Pipeline([ # Give low weight\n",
    "                    ('Radiation', Keywords_Light()),  # returns a list of dicts\n",
    "                    ('vect', DictVectorizer())  # list of dicts -> feature matrix\n",
    "        ])),            \n",
    "        ('key_words_albedo', Pipeline([ # Give low weight\n",
    "                    ('Radiation', Keywords_Albedo()),  # returns a list of dicts\n",
    "                    ('vect', DictVectorizer())  # list of dicts -> feature matrix\n",
    "        ])),\n",
    "        ('key_words_radiate', Pipeline([ # Give low weight\n",
    "                    ('Radiation', Keywords_Radiation()),  # returns a list of dicts\n",
    "                    ('vect', DictVectorizer())  # list of dicts -> feature matrix\n",
    "        ])),\n",
    "        ('key_words_trap', Pipeline([ # Give low weight\n",
    "                    ('Radiation', Trap_Radiation()),  # returns a list of dicts\n",
    "                    ('vect', DictVectorizer())  # list of dicts -> feature matrix\n",
    "        ])),\n",
    "        ('bag_of', Pipeline([\n",
    "                    ('vect', CountVectorizer(ngram_range=(1, 3), tokenizer=LemmaTokenizer(),  \n",
    "                                              max_df=0.25, max_features= 15000, token_pattern=r'\\b\\w+\\b', \n",
    "                                              stop_words=\"english\"))\n",
    "                    #('tfidf_transformer', TfidfTransformer(use_idf = True, norm='l2'))\n",
    "        ]))\n",
    "    ],\n",
    "    # weight components in FeatureUnion\n",
    "        transformer_weights={\n",
    "            'body_stats': 1.0,        \n",
    "            'key_words_dark': 1.0,\n",
    "            'key_words_light': 1.0,\n",
    "            'key_words_albedo': 1.0,        \n",
    "            'key_words_radiate': 1.0,\n",
    "            'key_words_trap': 1.0,\n",
    "            'bag_of': 1.0        \n",
    "        },\n",
    "    )),\n",
    "    ('to_dense', DenseTransformer()), \n",
    "    ('feature_selection', SelectFromModel(ExtraTreesClassifier(), prefit=False)),\n",
    "    #('dim', LinearDiscriminantAnalysis(n_components=2)),\n",
    "    #('clf', SVC(kernel='linear'))  # classifier\n",
    "    ('clf', eclf_w)  # classifier\n",
    "])\n",
    "\n",
    "\n",
    "p_predictor = pipeline.fit(train_set['Answer'], \n",
    "                                  train_set.KIScore)\n",
    "\n",
    "predicted = p_predictor.predict(dev_set['Answer'].values)\n",
    "accuracy_score(dev_set.KIScore, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Plotting Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[ 13   0   0   0   0]\n",
      " [  0 165  13   2   0]\n",
      " [  0  37  56   4   0]\n",
      " [  0   7  22  33   2]\n",
      " [  0   0   1  15   3]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUwAAAEpCAYAAAD4Vxu2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOedC8oTpnHMh/T9P1mMqcBbAkwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25e01adacc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(dev_set.KIScore, predicted)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Graded answers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at wrong classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I think this because when i wear a black shirt all the heat soaks in and im hot so i know that Laura should do a light colored paint so that way if she does do a dark color then it will be soaked in heat.\n",
      "Graded as: 2\n",
      "Actual grade is 3\n",
      "\n",
      "Black adsorbs and white reflects. So light cloth must reflect the heat.\n",
      "Graded as: 3\n",
      "Actual grade is 4\n",
      "\n",
      "The light colored paint on the outside will reflect the heat back out from the car, also with \n",
      "the light colored fabric inside. But if there was dark colored fabric and paint it will\n",
      "absorb the heat in the car.\n",
      "Graded as: 3\n",
      "Actual grade is 4\n",
      "\n",
      "I choose the light colored because if it was dark the sun would reflect dark color\n",
      "Graded as: 3\n",
      "Actual grade is 2\n",
      "\n",
      "Because since a light colored paint will reflet the heat it will keep her car cool.\n",
      "Graded as: 2\n",
      "Actual grade is 3\n",
      "\n",
      "I chose, using light-colored fabric on the inside of the car, because if you use dark colored fabric it will heat up more and the the heat would heat up the air. If you use light colored fabric on the inside of the car it will conduct less heat.\n",
      "Graded as: 2\n",
      "Actual grade is 3\n",
      "\n",
      "She should use us light colored paint on the outside and a dark colored fabric on the inside. The light colored paint wil reflect the sun's light and, the dark colored fabric will absorb the heat on the inside of the car.\n",
      "Graded as: 3\n",
      "Actual grade is 4\n",
      "\n",
      "If you use light color fabric on the inside it will get less hot because dark colors attract sun light\n",
      "Graded as: 2\n",
      "Actual grade is 3\n",
      "\n",
      "Using a light-colored paint on the outside and light-colored fabric on the inside of the car will keep the car from getting too hot because light-colored material reflects heat energy from the sun while black colored materials absorb that heat.\n",
      "Graded as: 4\n",
      "Actual grade is 5\n",
      "\n",
      "Dark things heat up faster and absorb it. Light things do that but at a much slower pace and don't get as got.\n",
      "Graded as: 4\n",
      "Actual grade is 3\n",
      "\n",
      "I think the light colored things would be better because dark things abs\n",
      "Graded as: 2\n",
      "Actual grade is 3\n",
      "\n",
      "light colored fabric makes it so you are cooler on warm days, but black/dark colors absorbs the heat making the car warmer.\n",
      "Graded as: 2\n",
      "Actual grade is 3\n",
      "\n",
      "Light colored material reflect more light an energy than dark colored materials.\n",
      "Graded as: 5\n",
      "Actual grade is 4\n",
      "\n",
      "Dark colors get warmer faster.\n",
      "Graded as: 2\n",
      "Actual grade is 3\n",
      "\n",
      "Because the sun reflects off bright colors.\n",
      "Graded as: 2\n",
      "Actual grade is 3\n",
      "\n",
      "So the car won't absorb heat inside.\n",
      "Graded as: 3\n",
      "Actual grade is 2\n",
      "\n",
      "The light color on the outside of the car helps reflect light energy. The light color fabric in the inside also does the same but it reflects the energy from the inside of the car.\n",
      "Graded as: 5\n",
      "Actual grade is 4\n",
      "\n",
      "You need something bright to reflect the heat. \n",
      "Graded as: 3\n",
      "Actual grade is 2\n",
      "\n",
      "Use a dark colored fabric because when the sunlight hits the window the fabric obsorbs it and has more power to obsorb it.\n",
      "Graded as: 3\n",
      "Actual grade is 4\n",
      "\n",
      "Light colored items have higher albedo. So it can reflect sunlight better than dark colored item which have low albedo. The lower the albedo, it's more likely to absorb the sunlight and gain heat.\n",
      "Graded as: 4\n",
      "Actual grade is 5\n",
      "\n",
      "because dark colors atract light.\n",
      "Graded as: 2\n",
      "Actual grade is 3\n",
      "\n",
      "dark colored paint will exsorb more heat\n",
      "Graded as: 2\n",
      "Actual grade is 3\n",
      "\n",
      "Dark colors tend to absorb heat and using light colors would help reflect some of the electromagnetic radiation penetrating through the car's windows. If more radiation is being reflected, then that means that more infrared radiation is being reflected too.\n",
      "Graded as: 4\n",
      "Actual grade is 5\n",
      "\n",
      "Using light colored fabric keeps the air cool and reflects the heat molecules.\n",
      "Graded as: 4\n",
      "Actual grade is 2\n",
      "\n",
      "I have picked a lighter color because in the solar oven if you have a darker color it will stay with it and it will heat up super fast so chose a ligter color and the sun will not go after it.\n",
      "Graded as: 2\n",
      "Actual grade is 3\n",
      "\n",
      "The heat reflects the light.\n",
      "Graded as: 2\n",
      "Actual grade is 3\n",
      "\n",
      "We would use light color on the outside because it would reflect it out instead of absorbing it and the dark color inside would trap the temperature.\n",
      "Graded as: 3\n",
      "Actual grade is 4\n",
      "\n",
      "I chose using a light-colored paint on the outside of the car because light paint will reflect the sun as the dark paint will absorb the heat. I also chose use light-colored fabric on the inside of the car because of the same thing.\n",
      "Graded as: 3\n",
      "Actual grade is 4\n",
      "\n",
      "Choosing a light color paint will help reflect some of that ultraviolet radiation from the sun because if you have a dark colored car, the darker color will absorb a lot of the heat from the sun, increasing the temperature. Paint color is a important factor for the temperature on the inside and outside of your car. So chose a light colored paint for your car if you live in a warm place. Also depending on where you live will affect what paint type you want. \n",
      "Graded as: 4\n",
      "Actual grade is 2\n",
      "\n",
      "It will help her because if she has a light-colored car it will reflect heat but if she has a dark colored car it will absorb heat.\n",
      "\n",
      "Graded as: 3\n",
      "Actual grade is 4\n",
      "\n",
      "Dark would not work because the sun is attracted to dark colors, not light colors.  So the sun will bounce off the light colors.\n",
      "Graded as: 2\n",
      "Actual grade is 3\n",
      "\n",
      "Light colored fabrics reflect more light rays than darker colors, which absorbs the suns rays. \n",
      "Graded as: 3\n",
      "Actual grade is 5\n",
      "\n",
      "I picked the dark because he dark can reflect off the black fabric or paint\n",
      "Graded as: 3\n",
      "Actual grade is 2\n",
      "\n",
      "It absorbs less heat.\n",
      "Graded as: 3\n",
      "Actual grade is 2\n",
      "\n",
      "it coloers the car with the dark paint becuse it the dark paint coloer it by the the dark paint isorb the heat.\n",
      "Graded as: 2\n",
      "Actual grade is 3\n",
      "\n",
      "Light colors prevent heat from going inside and creating conduction. Dark colors take the heat and seal it so that it goes inside. So if your car is hot, it's probably because you have dark colors on the inside and/ or outside.\n",
      "Graded as: 2\n",
      "Actual grade is 4\n",
      "\n",
      "Anything light colored reflects solar energy, this is called having a high albedo. Albedo is how much an objects reflects. If Laura wanted a hot car, she would use black paint and black fabric because black absorbs solar energy rather than reflecting it. \n",
      "Graded as: 4\n",
      "Actual grade is 5\n",
      "\n",
      "dark color  absorbs sunlight and light color reflects sunlight\n",
      "Graded as: 4\n",
      "Actual grade is 5\n",
      "\n",
      "I think that using a light colored paint on the outside of the car will prevent the car getting hotter because the lighter the color will be the - the shinier it is to bounce sun rays back to the atmosphere.\n",
      "Graded as: 2\n",
      "Actual grade is 4\n",
      "\n",
      "I think it should be a light colored fabric because according to other peoples solar ovens they used dark construction paper on the inside and it was way hotter on degrees than others so maybe the lighter the better.\n",
      "Graded as: 3\n",
      "Actual grade is 2\n",
      "\n",
      "The darker the color the more the heat gets attarcted to it the lighter the color the heat does not get attracted as much.\n",
      "Graded as: 2\n",
      "Actual grade is 3\n",
      "\n",
      "You would need a light colored car because dark colors attract and absorb heat. I know this because my dads car is always outside on the seats are dark colored.  It is always hot when you get in.\n",
      "Graded as: 2\n",
      "Actual grade is 3\n",
      "\n",
      "Dark colors get hotter than lighter colors. Dark colors attract radiation and lighter colors don't.\n",
      "Graded as: 2\n",
      "Actual grade is 3\n",
      "\n",
      "Darker colors(such as black) absorb the heat and sunlight more efficiently so it would cause Laura's car to become hotter. That is why using a lighter color paint for her care would be more efficinent because lighter colors reflect light and heat off better.\n",
      "Graded as: 4\n",
      "Actual grade is 5\n",
      "\n",
      "This is right because this paint will reflect the heat.\n",
      "Graded as: 3\n",
      "Actual grade is 2\n",
      "\n",
      "If the color of the paint should be light because if the color was dark then that means that it will attract the sun. You want light colored seats so they don't fade and it won't attract heat.\n",
      "Graded as: 2\n",
      "Actual grade is 3\n",
      "\n",
      "I said those were my chooses because sun rays are attracted to darker colored objects rather than lighter colored objects.\n",
      "Graded as: 2\n",
      "Actual grade is 3\n",
      "\n",
      "Black it the most absorbent of all of the colors, therefore making dark colored paints, and fabric more absorbent making the car hot on a sunny day.\n",
      "Graded as: 2\n",
      "Actual grade is 3\n",
      "\n",
      "when you have a dark-colored paint on the outside of your car, it will absorb the most heat. and the  light-colored fabric on the inside of the car will not absorb a lot of the heat.\n",
      "\n",
      "Graded as: 3\n",
      "Actual grade is 4\n",
      "\n",
      "I know that darker a color the more light it will absorb and heat so if you have the light color car youre not going to absorb that much heat.\n",
      "Graded as: 3\n",
      "Actual grade is 4\n",
      "\n",
      "We would use light color on the outside because it would reflect it out instead of absorbing it and the dark color inside would trap the temperature inside. \n",
      "Graded as: 3\n",
      "Actual grade is 4\n",
      "\n",
      "light colors bounce the sun rays back towards the sun, dark colors on the other hand  attract the rays to the car.\n",
      "Graded as: 2\n",
      "Actual grade is 4\n",
      "\n",
      "Light colored fabric would allow for less radiation absorption \n",
      "Graded as: 2\n",
      "Actual grade is 4\n",
      "\n",
      "Darker colors absorb more of the light spectrum and lighter reflects almost all of the light spectrum.\n",
      "Graded as: 4\n",
      "Actual grade is 5\n",
      "\n",
      "lighter colors like white deflect energy but dark colors like black absorbs energy.\n",
      "Graded as: 4\n",
      "Actual grade is 3\n",
      "\n",
      "If I'm correct, black fabric or black itself attracts the sun and therefore causes the object or person wearing a piece of cloth that is black to heat up in time.\n",
      "Graded as: 2\n",
      "Actual grade is 3\n",
      "\n",
      "The paint will block of the sun light that wants to get out\n",
      "Graded as: 2\n",
      "Actual grade is 3\n",
      "\n",
      "I chose those answers because the sun will go to darker colors mostly black. But using light colors it will prevent this from happening.\n",
      "Graded as: 2\n",
      "Actual grade is 3\n",
      "\n",
      "dark attracts heat and light color reflects\n",
      "Graded as: 2\n",
      "Actual grade is 3\n",
      "\n",
      "I chose using a light colored fabric because it will block the heat and also because its a light colored fabric it will not absorb as much heat as a dark colored fabric.\n",
      "Graded as: 3\n",
      "Actual grade is 4\n",
      "\n",
      "I belive painting the car a light color and having light colored fabric inside the car reduces heat because white (or a light color) reflects all light and solar energy- so Laura's car can stay cooler.\n",
      "Graded as: 3\n",
      "Actual grade is 4\n",
      "\n",
      "I think it should have white colored paint because,if she used something black it would make it hotter because the white could be used as a reflector, and black could be used as a heater when its hot, that also works with t-shirts.\n",
      "Graded as: 2\n",
      "Actual grade is 3\n",
      "\n",
      "If you have lighter colors, the less light will be absorbed, making it cooler inside the car. \n",
      "Graded as: 2\n",
      "Actual grade is 3\n",
      "\n",
      "If the inside is white it wont keep the sun  in the fabric it has, but if its black it will totaly obsorbe the heat like a sponge.\n",
      "Graded as: 2\n",
      "Actual grade is 3\n",
      "\n",
      "dark colers conduct heat\n",
      "Graded as: 2\n",
      "Actual grade is 3\n",
      "\n",
      "Light colors tend to reflect the suns rays more than dark fabric.\n",
      "Graded as: 3\n",
      "Actual grade is 4\n",
      "\n",
      "You want to use lighter colors because dark colors attract the heat. If you have lighter colors then the heat bounces off the light colors.\n",
      "Graded as: 2\n",
      "Actual grade is 3\n",
      "\n",
      "the lighter the color the better because darker colors attract more sunlight\n",
      "Graded as: 3\n",
      "Actual grade is 2\n",
      "\n",
      "A light colored paint job would reflect the sunlight meaning the car would not absorb the heat. \n",
      "Graded as: 4\n",
      "Actual grade is 5\n",
      "\n",
      "The light colors will cause the light to be reflected whereas dark colors will absorb the light causing the light energy to turn into heat.\n",
      "Graded as: 4\n",
      "Actual grade is 5\n",
      "\n",
      "I think it is the light colored stuff because i know that if you where black than you are going to be hot. So it is like the same thing with cars if you lay dark colored stuff on it or inside of it. It will heat up.\n",
      "Graded as: 2\n",
      "Actual grade is 3\n",
      "\n",
      "dark colors heat up faster than light colors.\n",
      "Graded as: 2\n",
      "Actual grade is 3\n",
      "\n",
      "Light colors deflect heat while dark colors absorb heat.\n",
      "Graded as: 3\n",
      "Actual grade is 4\n",
      "\n",
      "A light colored fabric will help it cool because it won't absorb as much heat from the inside which will keep the car cool.\n",
      "Graded as: 2\n",
      "Actual grade is 3\n",
      "\n",
      "I chose to use a light colored aint and fabric because light colors like white reflects light. The car will be cool all day long. If she used dark colored fabric and paint they will absorb the liight and will make the car too hot.\n",
      "Graded as: 4\n",
      "Actual grade is 5\n",
      "\n",
      "Using any light colored paint or items would help out a lot because light colors, like white, doesn't absorb much heat from the sun. This means that anything with light colors will be cooler. On the other hand, dark colors, like black, absorbs all the heat from the sun. This means that anything with dark colors will be hotter.\n",
      "Graded as: 3\n",
      "Actual grade is 2\n",
      "\n",
      "I chose this because light colored things don't absorb all the colors making it less hot. When you have a black car or seats it can make your car very hot from the heat because it's asborbing all colors. \n",
      "Graded as: 2\n",
      "Actual grade is 3\n",
      "\n",
      "Light colered things reflect most light.\n",
      "Graded as: 3\n",
      "Actual grade is 4\n",
      "\n",
      "Because that reflects the sun light which has heat.\n",
      "Graded as: 3\n",
      "Actual grade is 4\n",
      "\n",
      "I chose A and C because they both represent light colors. I know that light colors reflect the sun and dark colors obsorb the sun.\n",
      "Graded as: 3\n",
      "Actual grade is 4\n",
      "\n",
      "Using light colors absorbs less light and the color outside the car does not matter because it still gets very hot inside the care at a very rapid pace. The color inside matters since the sun is hitting the things inside that is coming from the windows.\n",
      "Graded as: 3\n",
      "Actual grade is 4\n",
      "\n",
      "Light colors don't absorb much heat, unlike dark colors that do. The light colors will prevent the sun from heating up too much.\n",
      "Graded as: 3\n",
      "Actual grade is 4\n",
      "\n",
      "Light colored paint on the outside tends to reflect more solar radiation because the light color of the paint tends to reflect more solar radiation than a dark colored painted car. This will cause less solar radiation to become Infrared Radiation.\n",
      "Graded as: 4\n",
      "Actual grade is 5\n",
      "\n",
      "Dark colored fabric absorbs heat while light colored fabric reflects heat.\n",
      "Graded as: 3\n",
      "Actual grade is 4\n",
      "\n",
      "I chose this because the paint doesn't matter about the heat inside the car.If she uses dark colored fabric,the sun will reflect on it,then it will be very hot.So, if she uses light colored fabric it will stay a little cool in her car.\n",
      "Graded as: 3\n",
      "Actual grade is 2\n",
      "\n",
      "this will relflect all the heat.\n",
      "Graded as: 2\n",
      "Actual grade is 3\n",
      "\n",
      "Light colored things do not attract the sun. It won't get as hot as the dark colored paint that actually attracts the sun.\n",
      "Graded as: 2\n",
      "Actual grade is 3\n",
      "\n",
      "it will block the sunlight from going in the car\n",
      "Graded as: 2\n",
      "Actual grade is 3\n",
      "\n",
      "Dark colors absorb heat, while light colors absorb less than dark colors. So it would be rejecting more heat.\n",
      "Graded as: 3\n",
      "Actual grade is 4\n",
      "\n",
      "The car should have a light-colored paint on the outside of the car because having a light- colored paint will reflect the solar and UV radiation. This is called albeto. If some solar and UV rays do get in to car then the light-colored fabric will reflect it back.\n",
      "Graded as: 3\n",
      "Actual grade is 4\n",
      "\n",
      "Because dark colors absorb, Laura should use a light-colored  paint on the outside so that it heat doesn't go into the car. \n",
      "Graded as: 4\n",
      "Actual grade is 3\n",
      "\n",
      "The light colored paint will reflect the light from the sun better leading to the light from the sun having a harder time to enter the car, making it cooler.\n",
      "Graded as: 2\n",
      "Actual grade is 4\n",
      "\n",
      "I chose that because bright reflects and dark doesn't.\n",
      "Graded as: 2\n",
      "Actual grade is 3\n",
      "\n",
      "if you have a dark colored car than your car is more likely to be warmer when you leave your car out in the sun instead of a lighter colored car because the darker colored cars observe more sun energy. \n",
      "Graded as: 2\n",
      "Actual grade is 4\n",
      "\n",
      "The light colors reflect sunlight and heat while the dark colors absorb it.\n",
      "Graded as: 4\n",
      "Actual grade is 5\n",
      "\n",
      "I chose my answers because black absorbs heat, making it hotter. White, on the other hand, reflects heat making it cooler.\n",
      "Graded as: 4\n",
      "Actual grade is 5\n",
      "\n",
      "Light colors reflect the light. Dark colors absorb the light.\n",
      "Graded as: 4\n",
      "Actual grade is 5\n",
      "\n",
      "because the light colored paint will reflect the heat from the sun.\n",
      "Graded as: 3\n",
      "Actual grade is 2\n",
      "\n",
      "Lighter colored fabric on the inside of the car helps it to contract. And if using dark colors, the heat absorbs.\n",
      "Graded as: 2\n",
      "Actual grade is 4\n",
      "\n",
      "because it will stop the heat longer because it is thicker than the white color  fabric so it will reflect\n",
      "Graded as: 3\n",
      "Actual grade is 2\n",
      "\n",
      "Light colors reflect colors and the more colors it reflects, the more it stays cold.\n",
      "Graded as: 3\n",
      "Actual grade is 2\n",
      "\n",
      "The inside of the car would get hotter if it had lighter colored paint, and fabric instead of dark paint and light fabric because, if the outside was wight and the inside was wight the sun wouldn't absorb the light but instead reflects, and that would get stick in the car, but black paint would absorb the light, and your furniture stays cold.  \n",
      "Graded as: 4\n",
      "Actual grade is 3\n",
      "\n",
      "Light colors, such as white reflect the sun's rays, keeping the car cooler than a black car with dark leather because black and other dark colors absorb heat.\n",
      "Graded as: 4\n",
      "Actual grade is 5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_values = list(predicted)\n",
    "actual = dev_set.values.tolist()\n",
    "\n",
    "for (z,y) in zip(actual, predicted_values):\n",
    "    if (str(z[2]) == str(y)):\n",
    "        continue\n",
    "    else:\n",
    "        print(\"{}\".format(z[1]))\n",
    "        print(\"Graded as: {}\".format(str(y)))\n",
    "        print(\"Actual grade is {}\".format(str(z[2])))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use prediction probabilities to see confidence level of predictions and defer to manual grader if needed. Work with the prediction probability feature of each classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56767006132898201"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohen_kappa_score(dev_set.KIScore, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
